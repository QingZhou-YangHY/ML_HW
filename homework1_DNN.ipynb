{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 1: COVID-19 Cases Prediction (Regression)**","metadata":{}},{"cell_type":"markdown","source":"# 全连接神经网络 使用的是**DNN** (Deep Neural Network，深度神经网络)/**MLP**多层感知机/**FCNN** 全连接神经网络。这个模型包含了三层隐藏层。\n## 深度神经网络 (Deep Neural Network / DNN)：当一个全连接神经网络 (MLP) 包含多个隐藏层时，它就被称为深度神经网络。全连接神经网络 (Fully Connected Neural Network / FCNN) 或 多层感知机 (Multi-Layer Perceptron / MLP)：这是最基础的神经网络类型，每一层的神经元都与前一层的所有神经元相连。你的模型就是这种架构。\n## 当一个MLP变得足够“深”（拥有足够的隐藏层），它就晋升为DNN了。EnhancedModel 既是一个全连接神经网络/多层感知机，也是一个深度神经网络。","metadata":{}},{"cell_type":"markdown","source":"# **新收获**\n## **超参数**是在训练过程开始之前**手动设置的配置变量**。是自己设置的\n## **参数**是模型在训练过程中**从数据中自动学习到的变量**。是模型自己算出来,学习到的","metadata":{}},{"cell_type":"code","source":"!wget -O covid_train.csv https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0\n!wget -O covid_test.csv https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T12:18:21.789197Z","iopub.execute_input":"2025-06-25T12:18:21.789484Z","iopub.status.idle":"2025-06-25T12:18:24.623542Z","shell.execute_reply.started":"2025-06-25T12:18:21.789459Z","shell.execute_reply":"2025-06-25T12:18:24.622810Z"},"collapsed":true,"jupyter":{"source_hidden":true,"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"--2025-06-25 12:18:21--  https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0\nResolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://www.dropbox.com/scl/fi/ewl0ff7lviu0s7f53jp9o/covid.train.csv?rlkey=pocojbo26thh2ncv0xkxfafiv&dl=0 [following]\n--2025-06-25 12:18:22--  https://www.dropbox.com/scl/fi/ewl0ff7lviu0s7f53jp9o/covid.train.csv?rlkey=pocojbo26thh2ncv0xkxfafiv&dl=0\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://ucdf9f6e14e08fb1a6e5df2c0e95.dl.dropboxusercontent.com/cd/0/inline/CsT9_S_6w8sde5r7ck1j_e1Dwf2wkTdAz_hy4iZ6yfYefjNBfQZ4LE67qRtnHrA--NZoKAzTR3XWMq9aNZqKZdUz1KzALyGqzvp2IALxguR9IwmHMCmooZAlhLxzaq3htVdIZD1eZl5hNHtswe0xFil1/file# [following]\n--2025-06-25 12:18:22--  https://ucdf9f6e14e08fb1a6e5df2c0e95.dl.dropboxusercontent.com/cd/0/inline/CsT9_S_6w8sde5r7ck1j_e1Dwf2wkTdAz_hy4iZ6yfYefjNBfQZ4LE67qRtnHrA--NZoKAzTR3XWMq9aNZqKZdUz1KzALyGqzvp2IALxguR9IwmHMCmooZAlhLxzaq3htVdIZD1eZl5hNHtswe0xFil1/file\nResolving ucdf9f6e14e08fb1a6e5df2c0e95.dl.dropboxusercontent.com (ucdf9f6e14e08fb1a6e5df2c0e95.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\nConnecting to ucdf9f6e14e08fb1a6e5df2c0e95.dl.dropboxusercontent.com (ucdf9f6e14e08fb1a6e5df2c0e95.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2162766 (2.1M) [text/plain]\nSaving to: ‘covid_train.csv’\n\ncovid_train.csv     100%[===================>]   2.06M  --.-KB/s    in 0.07s   \n\n2025-06-25 12:18:23 (27.5 MB/s) - ‘covid_train.csv’ saved [2162766/2162766]\n\n--2025-06-25 12:18:23--  https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0\nResolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://www.dropbox.com/scl/fi/0dewy98wqemuhraq1pi9s/covid.test.csv?rlkey=6x7r7z3hq8pvquke1bj8rqwgo&dl=0 [following]\n--2025-06-25 12:18:23--  https://www.dropbox.com/scl/fi/0dewy98wqemuhraq1pi9s/covid.test.csv?rlkey=6x7r7z3hq8pvquke1bj8rqwgo&dl=0\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://uca81212d67982629358da466ceb.dl.dropboxusercontent.com/cd/0/inline/CsRYrY7HK2t5IpD0fuap0k3JX9elwG0_w1t-8SVTZ_0RCPJ5QhOJ_hRXIIdsz5BtRzhnWpLiX6ovP7ynu75oTnkaJApXAI7dToCKpo1A8P8htgvEIiQ0wgY9bXwU7HXa3wjpPXl7lJwwWNDMavrMH7bL/file# [following]\n--2025-06-25 12:18:24--  https://uca81212d67982629358da466ceb.dl.dropboxusercontent.com/cd/0/inline/CsRYrY7HK2t5IpD0fuap0k3JX9elwG0_w1t-8SVTZ_0RCPJ5QhOJ_hRXIIdsz5BtRzhnWpLiX6ovP7ynu75oTnkaJApXAI7dToCKpo1A8P8htgvEIiQ0wgY9bXwU7HXa3wjpPXl7lJwwWNDMavrMH7bL/file\nResolving uca81212d67982629358da466ceb.dl.dropboxusercontent.com (uca81212d67982629358da466ceb.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\nConnecting to uca81212d67982629358da466ceb.dl.dropboxusercontent.com (uca81212d67982629358da466ceb.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 638359 (623K) [text/plain]\nSaving to: ‘covid_test.csv’\n\ncovid_test.csv      100%[===================>] 623.40K  --.-KB/s    in 0.06s   \n\n2025-06-25 12:18:24 (11.0 MB/s) - ‘covid_test.csv’ saved [638359/638359]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport math\nimport os\nimport csv\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, f_regression\nprint(\"Import Complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T12:37:15.344829Z","iopub.execute_input":"2025-06-25T12:37:15.345168Z","iopub.status.idle":"2025-06-25T12:37:16.049861Z","shell.execute_reply.started":"2025-06-25T12:37:15.345149Z","shell.execute_reply":"2025-06-25T12:37:16.049102Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Import Complete!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"class COVID19Dataset(Dataset):\n    def __init__(self, x, y=None,scaler = None):\n        self.scaler = scaler\n        if y is not None:\n            self.scaler = StandardScaler()\n            self.x = self.scaler.fit_transform(x)\n            self.y = torch.FloatTensor(y)\n        else:\n            if scaler is None:\n                raise ValueError(\"测试机需要提供预拟合的scaler\")\n            self.scaler =  scaler\n            self.x = self.scaler.transform(x)\n            self.y = None\n\n    def __getitem__(self, idx):\n        if self.y is None:\n            return torch.FloatTensor(self.x[idx])\n        return torch.FloatTensor(self.x[idx]), self.y[idx]\n\n    def __len__(self):\n        return len(self.x)\n\nprint(\"Class is defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:33:52.198703Z","iopub.execute_input":"2025-06-25T13:33:52.199611Z","iopub.status.idle":"2025-06-25T13:33:52.206556Z","shell.execute_reply.started":"2025-06-25T13:33:52.199574Z","shell.execute_reply":"2025-06-25T13:33:52.205760Z"}},"outputs":[{"name":"stdout","text":"Class is defined!\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"def select_feat(train_data, valid_data, test_data, select_all=True):\n    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n\n    if select_all:\n        feat_idx = list(range(raw_x_train.shape[1]))\n    else:\n        # 使用SelectKBest选择最重要的10个特征\n        selector = SelectKBest(f_regression, k=10)\n        selector.fit(raw_x_train, y_train)\n        feat_idx = selector.get_support(indices=True)\n        \n    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid\nprint(\"func is defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T12:53:47.244376Z","iopub.execute_input":"2025-06-25T12:53:47.244700Z","iopub.status.idle":"2025-06-25T12:53:47.250817Z","shell.execute_reply.started":"2025-06-25T12:53:47.244679Z","shell.execute_reply":"2025-06-25T12:53:47.249914Z"}},"outputs":[{"name":"stdout","text":"func is defined!\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"class EnhancedModel(nn.Module):\n    def __init__(self, input_dim):\n        super(EnhancedModel, self).__init__()\n        \n        self.net = nn.Sequential(\n            # 全连接层,它接收 input_dim 个特征作为输入。它产生 64 个输出特征。这个层有 input_dim * 64 个权重和 64 个偏置。\n            nn.Linear(input_dim, 64),\n            # 批量归一化层,它对前一层（有 64 个特征）的输出在批次维度上进行归一化.它学习 64 个 gamma（缩放）参数和 64 个 beta（偏移）参数。\n            nn.BatchNorm1d(64),\n            # 激活函数,这允许负数输入也有小的梯度，有助于防止“ReLU死亡”问题。目的：引入非线性，使网络能够学习复杂的模式。\n            nn.LeakyReLU(0.1),\n            # Dropout 层,在训练期间，它会随机地将批次中每个样本的 30% (0.3) 的输入特征设置为零.目的：通过强制网络学习更鲁棒的特征并防止神经元之间的协同适应来防止过拟合。\n            nn.Dropout(0.3),\n\n            # nn.Linear(64, 32): 另一个全连接层。接收前一个块的 64 个特征。输出 32 个特征。参数：64 * 32 个权重和 32 个偏置。\n            nn.Linear(64, 32),\n            # 32 个特征的批量归一化。32 个 gamma 和 32 个 beta 参数。\n            nn.BatchNorm1d(32),\n            # Leaky ReLU 激活函数。\n            nn.LeakyReLU(0.1),\n            # Dropout 层，随机将 20% 的特征设置为零。目的：进一步正则化。\n            nn.Dropout(0.2),\n\n            # 全连接层。没有 Dropout 或 BatchNorm,接收 32 个特征。输出 16 个特征。参数：32 * 16 个权重和 16 个偏置。\n            nn.Linear(32, 16),\n            # Leaky ReLU 激活函数。\n            nn.LeakyReLU(0.1),\n            \n            #  最后一个全连接层。输出1 个特征。这个单一输出表明该模型可能设计用于回归任务（预测一个连续值）或二分类（如果在此层之后应用 Sigmoid 激活）。\n            # 参数：16 * 1 个权重和 1 个偏置。\n            nn.Linear(16, 1)\n        )\n        \n        # 初始化网络层的权重和偏置.\n        self._init_weights()\n    \n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                \"\"\"\n                m.weight: 指的是当前 nn.Linear 层的权重张量。\n\n                mode='fan_in': 表示初始化的方差应该基于层的输入单元数量（fan-in）。\n\n                nonlinearity='leaky_relu': 指定 Kaiming 初始化应该根据使用 Leaky ReLU 激活函数的层进行校准。\n                \"\"\"\n                # 这种初始化策略常用于 ReLU 类激活函数，有助于防止训练过程中梯度消失或爆炸，尤其是在深度网络中。\n                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n                # 这行代码将 nn.Linear 层的偏置初始化为常量值 0.1。目的：一个小的正偏置有时有助于在训练初期激活 ReLU 类神经元。\n                nn.init.constant_(m.bias, 0.1)\n\n    def forward(self, x):\n        return self.net(x).squeeze(1)\n        # self.net(x): 这是关键所在。输入张量 x 被传入 nn.Sequential 容器 (self.net)，它会按顺序通过所有定义的层进行处理。\n        # .squeeze(1): self.net(x) 的输出通常形状为 (batch_size, 1)。squeeze(1) 会移除索引为 1 的大小为 1 的维度。\n        # 目的：这通常用于回归任务，因为你想要一个扁平的预测张量，而不是一个带有冗余的、大小为 1 的维度的张量。\nprint(\"Model is defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T12:53:49.071885Z","iopub.execute_input":"2025-06-25T12:53:49.072149Z","iopub.status.idle":"2025-06-25T12:53:49.078921Z","shell.execute_reply.started":"2025-06-25T12:53:49.072131Z","shell.execute_reply":"2025-06-25T12:53:49.078071Z"}},"outputs":[{"name":"stdout","text":"Model is defined!\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"def trainer(train_loader, valid_loader, model, config, device):\n    # 使用更鲁棒的损失函数\n    criterion = nn.HuberLoss(delta=1.0)  # 对异常值更鲁棒\n    \n    # 优化器改进\n    optimizer = torch.optim.AdamW(\n        model.parameters(), \n        lr=config['learning_rate'],\n        weight_decay=1e-4  # L2正则化\n    )\n    \n    # 学习率调度\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, \n        mode='min',\n        patience=20,\n        factor=0.5,\n        verbose=True\n    )\n    \n    writer = SummaryWriter()\n    os.makedirs('/kaggle/working/models', exist_ok=True)\n    \n    best_loss = float('inf')\n    early_stop_count = 0\n    \n    for epoch in range(config['n_epochs']):\n        model.train()\n        train_loss = []\n        train_pbar = tqdm(train_loader, desc=f'Epoch [{epoch+1}/{config[\"n_epochs\"]}]')\n        \n        for x, y in train_pbar:\n            x, y = x.to(device), y.to(device)\n\n            # 清除优化器中所有累积的梯度。\n            # 梯度在每次反向传播时都会累积，所以在新的批次开始时需要清零。\n            optimizer.zero_grad()\n            # 执行前向传播：将输入 x 传入模型，得到预测值 pred。\n            pred = model(x)\n            loss = criterion(pred, y)\n            \n            # 梯度裁剪：限制模型参数的梯度范数不超过 1.0。\n            # 这有助于防止梯度爆炸问题，尤其是在训练深层网络或使用某些优化器时。\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            # 执行反向传播：计算损失相对于模型所有可学习参数的梯度。\n            # 这些梯度会存储在每个参数的 .grad 属性中。\n            loss.backward()\n            # 更新模型参数：根据计算出的梯度和优化器（例如 SGD, Adam 等）的规则来更新模型的权重和偏置。\n            optimizer.step()\n            \n            train_loss.append(loss.item())\n            train_pbar.set_postfix({'loss': loss.item()})\n        \n        # 验证阶段\n        model.eval()\n        valid_loss = []\n        # 禁用梯度计算：\n        # 在验证阶段，我们不需要计算梯度，因为我们不进行参数更新。\n        # 禁用梯度可以减少内存消耗并加速计算。\n        with torch.no_grad():\n            for x, y in valid_loader:\n                x, y = x.to(device), y.to(device)\n                pred = model(x)\n                loss = criterion(pred, y)\n                valid_loss.append(loss.item())\n        \n        # 计算平均损失\n        mean_train_loss = np.mean(train_loss)\n        mean_valid_loss = np.mean(valid_loss)\n        \n        # 学习率调整\n        # scheduler.step() 用于根据验证损失来调整学习率。\n        # 例如，如果使用 ReduceLROnPlateau 调度器，当验证损失停止改善时，学习率可能会降低。\n        scheduler.step(mean_valid_loss)\n        \n        # 记录和打印\n        writer.add_scalars('Loss', {\n            'train': mean_train_loss,\n            'valid': mean_valid_loss\n        }, epoch)\n        \n        print(f'Epoch {epoch+1}: Train Loss: {mean_train_loss:.4f} | Valid Loss: {mean_valid_loss:.4f}')\n        \n        # 早停机制\n        # 如果当前 epoch 的验证损失低于历史最佳验证损失\n        if mean_valid_loss < best_loss:\n            best_loss = mean_valid_loss # 更新最佳损失\n            # 保存当前模型的权重（state_dict），因为这是目前表现最好的模型。\n            torch.save(model.state_dict(), config['save_path'])\n            early_stop_count = 0 # 重置早停计数器\n        else:\n            early_stop_count += 1 # 否则，增加早停计数\n            # 如果早停计数达到预设的阈值 (config['early_stop'])\n            if early_stop_count >= config['early_stop']:\n                print(f'\\nEarly stopping at epoch {epoch+1}')\n                break\n\nprint(\"trainer is defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T12:53:51.113119Z","iopub.execute_input":"2025-06-25T12:53:51.113393Z","iopub.status.idle":"2025-06-25T12:53:51.123853Z","shell.execute_reply.started":"2025-06-25T12:53:51.113373Z","shell.execute_reply":"2025-06-25T12:53:51.123230Z"}},"outputs":[{"name":"stdout","text":"trainer is defined!\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"def save_pred(preds,file):\n    with open(file,'w') as fp:\n        writer = csv.writer(fp)\n        writer.writerow(['id','tested_positive'])\n        for i,p in enumerate(preds):\n            writer.writerow([i,p])\n\nprint(\"func is defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:03:07.451252Z","iopub.execute_input":"2025-06-25T13:03:07.451611Z","iopub.status.idle":"2025-06-25T13:03:07.457205Z","shell.execute_reply.started":"2025-06-25T13:03:07.451584Z","shell.execute_reply":"2025-06-25T13:03:07.456468Z"}},"outputs":[{"name":"stdout","text":"func is defined!\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"def main():\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    \n    config = {\n        'seed': 5201314,\n        'select_all': False,  # 使用特征选择\n        'valid_ratio': 0.2,\n        'n_epochs': 1000,\n        'batch_size': 512,\n        'learning_rate': 1e-3,\n        'early_stop': 100,\n        'save_path': '/kaggle/working/models/best_model.ckpt'\n    }\n\n    # 设置随机种子\n    torch.manual_seed(config['seed'])\n    np.random.seed(config['seed'])\n    \n    # 加载数据\n    train_data = pd.read_csv('/kaggle/working/covid_train.csv').values\n    test_data = pd.read_csv('/kaggle/working/covid_test.csv').values\n    \n    # 数据分割\n    train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n    \n    # 特征选择\n    x_train, x_valid, x_test, y_train, y_valid = select_feat(\n        train_data, valid_data, test_data, config['select_all'])\n    \n    print(f'Selected {x_train.shape[1]} features')\n    \n    # 创建数据集\n    train_dataset = COVID19Dataset(x_train, y_train)\n    fitted_scaler = train_dataset.scaler\n    valid_dataset = COVID19Dataset(x_valid, y_valid,scaler=fitted_scaler)\n    test_dataset = COVID19Dataset(x_test,scaler=fitted_scaler)\n    \n    # 数据加载器\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=config['batch_size'], \n        shuffle=True, \n        pin_memory=True,\n        num_workers=2\n    )\n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size=config['batch_size'],\n        shuffle=False,\n        pin_memory=True\n    )\n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=config['batch_size'],\n        shuffle=False,\n        pin_memory=True\n    )\n    \n    # 初始化模型\n    model = EnhancedModel(input_dim=x_train.shape[1]).to(device)\n    \n    # 训练模型\n    trainer(train_loader, valid_loader, model, config, device)\n    \n    # 预测和保存结果\n    model.load_state_dict(torch.load(config['save_path']))\n    preds = predict(test_loader, model, device)\n    save_pred(preds, 'pred.csv')\n\n# 这个结构提供了一个“入口点”，让你可以在一个文件中同时实现两种功能：\n#作为可执行的脚本（直接运行）。\n#作为可导入的模块（供其他文件调用）。\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:40:32.719031Z","iopub.execute_input":"2025-06-25T13:40:32.719744Z","iopub.status.idle":"2025-06-25T13:41:23.809439Z","shell.execute_reply.started":"2025-06-25T13:40:32.719717Z","shell.execute_reply":"2025-06-25T13:41:23.808544Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Selected 10 features\n","output_type":"stream"},{"name":"stderr","text":"Epoch [1/1000]: 100%|██████████| 5/5 [00:00<00:00, 34.40it/s, loss=15.9]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Loss: 15.8823 | Valid Loss: 16.7533\n","output_type":"stream"},{"name":"stderr","text":"Epoch [2/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.72it/s, loss=14.9]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Train Loss: 15.5527 | Valid Loss: 16.5099\n","output_type":"stream"},{"name":"stderr","text":"Epoch [3/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.60it/s, loss=14.7]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Train Loss: 15.2438 | Valid Loss: 16.1827\n","output_type":"stream"},{"name":"stderr","text":"Epoch [4/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.46it/s, loss=14.2]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Train Loss: 14.9298 | Valid Loss: 15.8384\n","output_type":"stream"},{"name":"stderr","text":"Epoch [5/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.58it/s, loss=14.5]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Train Loss: 14.6516 | Valid Loss: 15.4751\n","output_type":"stream"},{"name":"stderr","text":"Epoch [6/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.88it/s, loss=14.4]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Train Loss: 14.3663 | Valid Loss: 15.1395\n","output_type":"stream"},{"name":"stderr","text":"Epoch [7/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.63it/s, loss=15]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Train Loss: 14.1208 | Valid Loss: 14.8425\n","output_type":"stream"},{"name":"stderr","text":"Epoch [8/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.06it/s, loss=14]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Train Loss: 13.7844 | Valid Loss: 14.5818\n","output_type":"stream"},{"name":"stderr","text":"Epoch [9/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.09it/s, loss=13.1]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Train Loss: 13.4281 | Valid Loss: 14.3257\n","output_type":"stream"},{"name":"stderr","text":"Epoch [10/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.92it/s, loss=13.2]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Train Loss: 13.1617 | Valid Loss: 14.0501\n","output_type":"stream"},{"name":"stderr","text":"Epoch [11/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.03it/s, loss=12.8]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Train Loss: 12.7892 | Valid Loss: 13.7729\n","output_type":"stream"},{"name":"stderr","text":"Epoch [12/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.24it/s, loss=12.1]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Train Loss: 12.4495 | Valid Loss: 13.4863\n","output_type":"stream"},{"name":"stderr","text":"Epoch [13/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.69it/s, loss=11.9]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Train Loss: 12.0950 | Valid Loss: 13.1444\n","output_type":"stream"},{"name":"stderr","text":"Epoch [14/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.94it/s, loss=11.5]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Train Loss: 11.6664 | Valid Loss: 12.7698\n","output_type":"stream"},{"name":"stderr","text":"Epoch [15/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.14it/s, loss=11.8]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Train Loss: 11.2967 | Valid Loss: 12.3608\n","output_type":"stream"},{"name":"stderr","text":"Epoch [16/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.11it/s, loss=10.8]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Train Loss: 10.8649 | Valid Loss: 11.9113\n","output_type":"stream"},{"name":"stderr","text":"Epoch [17/1000]: 100%|██████████| 5/5 [00:00<00:00, 33.02it/s, loss=11.2]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Train Loss: 10.3626 | Valid Loss: 11.4024\n","output_type":"stream"},{"name":"stderr","text":"Epoch [18/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.79it/s, loss=9.67]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Train Loss: 9.7560 | Valid Loss: 10.8077\n","output_type":"stream"},{"name":"stderr","text":"Epoch [19/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.39it/s, loss=8.31]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Train Loss: 9.0813 | Valid Loss: 10.1276\n","output_type":"stream"},{"name":"stderr","text":"Epoch [20/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.43it/s, loss=8.73]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Train Loss: 8.5606 | Valid Loss: 9.4013\n","output_type":"stream"},{"name":"stderr","text":"Epoch [21/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.03it/s, loss=8.3]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Train Loss: 7.8680 | Valid Loss: 8.6004\n","output_type":"stream"},{"name":"stderr","text":"Epoch [22/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.83it/s, loss=6.28]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Train Loss: 7.0300 | Valid Loss: 7.7403\n","output_type":"stream"},{"name":"stderr","text":"Epoch [23/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.73it/s, loss=5.24]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23: Train Loss: 6.2927 | Valid Loss: 6.5916\n","output_type":"stream"},{"name":"stderr","text":"Epoch [24/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.64it/s, loss=4.96]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24: Train Loss: 5.4554 | Valid Loss: 5.1852\n","output_type":"stream"},{"name":"stderr","text":"Epoch [25/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.41it/s, loss=4.16]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25: Train Loss: 4.6316 | Valid Loss: 3.7552\n","output_type":"stream"},{"name":"stderr","text":"Epoch [26/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.35it/s, loss=3.85]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26: Train Loss: 3.9034 | Valid Loss: 2.3178\n","output_type":"stream"},{"name":"stderr","text":"Epoch [27/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.03it/s, loss=3.04]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27: Train Loss: 3.0688 | Valid Loss: 1.6668\n","output_type":"stream"},{"name":"stderr","text":"Epoch [28/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.06it/s, loss=2.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28: Train Loss: 2.7402 | Valid Loss: 1.4656\n","output_type":"stream"},{"name":"stderr","text":"Epoch [29/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.81it/s, loss=2.27]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29: Train Loss: 2.4363 | Valid Loss: 1.2439\n","output_type":"stream"},{"name":"stderr","text":"Epoch [30/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.84it/s, loss=2.41]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30: Train Loss: 2.3441 | Valid Loss: 1.1482\n","output_type":"stream"},{"name":"stderr","text":"Epoch [31/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.77it/s, loss=2.02]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31: Train Loss: 2.2154 | Valid Loss: 0.9895\n","output_type":"stream"},{"name":"stderr","text":"Epoch [32/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.02it/s, loss=2.15]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32: Train Loss: 2.2096 | Valid Loss: 0.9106\n","output_type":"stream"},{"name":"stderr","text":"Epoch [33/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.04it/s, loss=2.27]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33: Train Loss: 2.2031 | Valid Loss: 0.9042\n","output_type":"stream"},{"name":"stderr","text":"Epoch [34/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.49it/s, loss=2.1]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34: Train Loss: 2.2080 | Valid Loss: 0.9429\n","output_type":"stream"},{"name":"stderr","text":"Epoch [35/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.25it/s, loss=1.89]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35: Train Loss: 2.0559 | Valid Loss: 1.0172\n","output_type":"stream"},{"name":"stderr","text":"Epoch [36/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.35it/s, loss=1.97]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36: Train Loss: 2.0156 | Valid Loss: 1.0270\n","output_type":"stream"},{"name":"stderr","text":"Epoch [37/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.25it/s, loss=1.98]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37: Train Loss: 2.0310 | Valid Loss: 1.0090\n","output_type":"stream"},{"name":"stderr","text":"Epoch [38/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.45it/s, loss=1.87]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38: Train Loss: 1.9700 | Valid Loss: 0.9445\n","output_type":"stream"},{"name":"stderr","text":"Epoch [39/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.94it/s, loss=2.15]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39: Train Loss: 2.0095 | Valid Loss: 0.9340\n","output_type":"stream"},{"name":"stderr","text":"Epoch [40/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.88it/s, loss=2.02]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40: Train Loss: 2.0496 | Valid Loss: 0.9359\n","output_type":"stream"},{"name":"stderr","text":"Epoch [41/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.39it/s, loss=1.92]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41: Train Loss: 1.9430 | Valid Loss: 1.0596\n","output_type":"stream"},{"name":"stderr","text":"Epoch [42/1000]: 100%|██████████| 5/5 [00:00<00:00, 34.37it/s, loss=1.92]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42: Train Loss: 1.9905 | Valid Loss: 1.1381\n","output_type":"stream"},{"name":"stderr","text":"Epoch [43/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.03it/s, loss=2.05]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43: Train Loss: 1.9951 | Valid Loss: 0.9418\n","output_type":"stream"},{"name":"stderr","text":"Epoch [44/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.10it/s, loss=1.94]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44: Train Loss: 1.9151 | Valid Loss: 0.8340\n","output_type":"stream"},{"name":"stderr","text":"Epoch [45/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.52it/s, loss=1.87]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45: Train Loss: 1.9010 | Valid Loss: 0.8479\n","output_type":"stream"},{"name":"stderr","text":"Epoch [46/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.52it/s, loss=1.84]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46: Train Loss: 1.9071 | Valid Loss: 0.8565\n","output_type":"stream"},{"name":"stderr","text":"Epoch [47/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.62it/s, loss=1.99]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47: Train Loss: 1.9456 | Valid Loss: 0.8567\n","output_type":"stream"},{"name":"stderr","text":"Epoch [48/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.44it/s, loss=1.99]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48: Train Loss: 1.9257 | Valid Loss: 0.8753\n","output_type":"stream"},{"name":"stderr","text":"Epoch [49/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.09it/s, loss=1.87]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49: Train Loss: 1.8951 | Valid Loss: 0.9034\n","output_type":"stream"},{"name":"stderr","text":"Epoch [50/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.46it/s, loss=1.79]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50: Train Loss: 1.8155 | Valid Loss: 0.9124\n","output_type":"stream"},{"name":"stderr","text":"Epoch [51/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.86it/s, loss=1.93]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 51: Train Loss: 1.8994 | Valid Loss: 0.8378\n","output_type":"stream"},{"name":"stderr","text":"Epoch [52/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.16it/s, loss=1.85]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 52: Train Loss: 1.9044 | Valid Loss: 0.7360\n","output_type":"stream"},{"name":"stderr","text":"Epoch [53/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.55it/s, loss=1.91]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 53: Train Loss: 1.8736 | Valid Loss: 0.6819\n","output_type":"stream"},{"name":"stderr","text":"Epoch [54/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.13it/s, loss=1.73]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 54: Train Loss: 1.8309 | Valid Loss: 0.6815\n","output_type":"stream"},{"name":"stderr","text":"Epoch [55/1000]: 100%|██████████| 5/5 [00:00<00:00, 41.12it/s, loss=1.98]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 55: Train Loss: 1.9035 | Valid Loss: 0.7489\n","output_type":"stream"},{"name":"stderr","text":"Epoch [56/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.15it/s, loss=1.82]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 56: Train Loss: 1.8392 | Valid Loss: 0.7687\n","output_type":"stream"},{"name":"stderr","text":"Epoch [57/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.61it/s, loss=1.91]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 57: Train Loss: 1.8169 | Valid Loss: 0.7522\n","output_type":"stream"},{"name":"stderr","text":"Epoch [58/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.16it/s, loss=1.82]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 58: Train Loss: 1.8509 | Valid Loss: 0.7548\n","output_type":"stream"},{"name":"stderr","text":"Epoch [59/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.23it/s, loss=2.01]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 59: Train Loss: 1.8932 | Valid Loss: 0.7815\n","output_type":"stream"},{"name":"stderr","text":"Epoch [60/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.14it/s, loss=1.76]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 60: Train Loss: 1.7974 | Valid Loss: 0.7809\n","output_type":"stream"},{"name":"stderr","text":"Epoch [61/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.53it/s, loss=2.09]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 61: Train Loss: 1.8041 | Valid Loss: 0.7452\n","output_type":"stream"},{"name":"stderr","text":"Epoch [62/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.36it/s, loss=1.9]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 62: Train Loss: 1.8473 | Valid Loss: 0.7442\n","output_type":"stream"},{"name":"stderr","text":"Epoch [63/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.05it/s, loss=1.79]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 63: Train Loss: 1.8660 | Valid Loss: 0.7150\n","output_type":"stream"},{"name":"stderr","text":"Epoch [64/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.55it/s, loss=1.93]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 64: Train Loss: 1.8464 | Valid Loss: 0.7066\n","output_type":"stream"},{"name":"stderr","text":"Epoch [65/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.41it/s, loss=1.92]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 65: Train Loss: 1.8175 | Valid Loss: 0.7819\n","output_type":"stream"},{"name":"stderr","text":"Epoch [66/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.73it/s, loss=1.93]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 66: Train Loss: 1.8188 | Valid Loss: 0.8108\n","output_type":"stream"},{"name":"stderr","text":"Epoch [67/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.99it/s, loss=1.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 67: Train Loss: 1.7666 | Valid Loss: 0.7764\n","output_type":"stream"},{"name":"stderr","text":"Epoch [68/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.92it/s, loss=1.77]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 68: Train Loss: 1.7475 | Valid Loss: 0.6827\n","output_type":"stream"},{"name":"stderr","text":"Epoch [69/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.68it/s, loss=1.68]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 69: Train Loss: 1.7483 | Valid Loss: 0.6673\n","output_type":"stream"},{"name":"stderr","text":"Epoch [70/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.42it/s, loss=1.73]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 70: Train Loss: 1.7814 | Valid Loss: 0.6386\n","output_type":"stream"},{"name":"stderr","text":"Epoch [71/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.15it/s, loss=1.85]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 71: Train Loss: 1.7801 | Valid Loss: 0.7161\n","output_type":"stream"},{"name":"stderr","text":"Epoch [72/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.21it/s, loss=1.65]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 72: Train Loss: 1.7713 | Valid Loss: 0.7937\n","output_type":"stream"},{"name":"stderr","text":"Epoch [73/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.68it/s, loss=1.81]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 73: Train Loss: 1.7438 | Valid Loss: 0.7858\n","output_type":"stream"},{"name":"stderr","text":"Epoch [74/1000]: 100%|██████████| 5/5 [00:00<00:00, 32.43it/s, loss=1.61]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 74: Train Loss: 1.6939 | Valid Loss: 0.6995\n","output_type":"stream"},{"name":"stderr","text":"Epoch [75/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.60it/s, loss=1.62]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 75: Train Loss: 1.6951 | Valid Loss: 0.6259\n","output_type":"stream"},{"name":"stderr","text":"Epoch [76/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.69it/s, loss=1.88]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 76: Train Loss: 1.7639 | Valid Loss: 0.6319\n","output_type":"stream"},{"name":"stderr","text":"Epoch [77/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.70it/s, loss=1.77]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 77: Train Loss: 1.7607 | Valid Loss: 0.6222\n","output_type":"stream"},{"name":"stderr","text":"Epoch [78/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.47it/s, loss=1.67]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 78: Train Loss: 1.7365 | Valid Loss: 0.6252\n","output_type":"stream"},{"name":"stderr","text":"Epoch [79/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.16it/s, loss=1.88]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 79: Train Loss: 1.7800 | Valid Loss: 0.6825\n","output_type":"stream"},{"name":"stderr","text":"Epoch [80/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.61it/s, loss=1.75]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 80: Train Loss: 1.7088 | Valid Loss: 0.7073\n","output_type":"stream"},{"name":"stderr","text":"Epoch [81/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.51it/s, loss=1.73]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 81: Train Loss: 1.7392 | Valid Loss: 0.7142\n","output_type":"stream"},{"name":"stderr","text":"Epoch [82/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.21it/s, loss=1.52]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 82: Train Loss: 1.6461 | Valid Loss: 0.7693\n","output_type":"stream"},{"name":"stderr","text":"Epoch [83/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.30it/s, loss=1.68]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 83: Train Loss: 1.6993 | Valid Loss: 0.6782\n","output_type":"stream"},{"name":"stderr","text":"Epoch [84/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.19it/s, loss=1.89]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 84: Train Loss: 1.7902 | Valid Loss: 0.5926\n","output_type":"stream"},{"name":"stderr","text":"Epoch [85/1000]: 100%|██████████| 5/5 [00:00<00:00,  7.05it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 85: Train Loss: 1.6912 | Valid Loss: 0.6043\n","output_type":"stream"},{"name":"stderr","text":"Epoch [86/1000]: 100%|██████████| 5/5 [00:00<00:00,  6.55it/s, loss=1.67]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 86: Train Loss: 1.6778 | Valid Loss: 0.6691\n","output_type":"stream"},{"name":"stderr","text":"Epoch [87/1000]: 100%|██████████| 5/5 [00:00<00:00,  7.01it/s, loss=1.57]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 87: Train Loss: 1.6738 | Valid Loss: 0.7501\n","output_type":"stream"},{"name":"stderr","text":"Epoch [88/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.54it/s, loss=1.78]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 88: Train Loss: 1.8059 | Valid Loss: 0.6854\n","output_type":"stream"},{"name":"stderr","text":"Epoch [89/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.28it/s, loss=1.57]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 89: Train Loss: 1.6427 | Valid Loss: 0.6158\n","output_type":"stream"},{"name":"stderr","text":"Epoch [90/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.66it/s, loss=1.82]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 90: Train Loss: 1.7012 | Valid Loss: 0.6676\n","output_type":"stream"},{"name":"stderr","text":"Epoch [91/1000]: 100%|██████████| 5/5 [00:00<00:00, 34.98it/s, loss=1.6] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 91: Train Loss: 1.6353 | Valid Loss: 0.7402\n","output_type":"stream"},{"name":"stderr","text":"Epoch [92/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.13it/s, loss=1.67]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 92: Train Loss: 1.6894 | Valid Loss: 0.7670\n","output_type":"stream"},{"name":"stderr","text":"Epoch [93/1000]: 100%|██████████| 5/5 [00:00<00:00, 33.98it/s, loss=1.72]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 93: Train Loss: 1.6588 | Valid Loss: 0.7161\n","output_type":"stream"},{"name":"stderr","text":"Epoch [94/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.10it/s, loss=1.93]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 94: Train Loss: 1.7372 | Valid Loss: 0.6535\n","output_type":"stream"},{"name":"stderr","text":"Epoch [95/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.69it/s, loss=1.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 95: Train Loss: 1.6881 | Valid Loss: 0.6274\n","output_type":"stream"},{"name":"stderr","text":"Epoch [96/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.24it/s, loss=1.59]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 96: Train Loss: 1.7309 | Valid Loss: 0.6679\n","output_type":"stream"},{"name":"stderr","text":"Epoch [97/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.78it/s, loss=1.67]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 97: Train Loss: 1.6626 | Valid Loss: 0.6359\n","output_type":"stream"},{"name":"stderr","text":"Epoch [98/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.84it/s, loss=1.74]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 98: Train Loss: 1.6371 | Valid Loss: 0.6562\n","output_type":"stream"},{"name":"stderr","text":"Epoch [99/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.59it/s, loss=1.56]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 99: Train Loss: 1.6770 | Valid Loss: 0.6367\n","output_type":"stream"},{"name":"stderr","text":"Epoch [100/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.06it/s, loss=1.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 100: Train Loss: 1.5931 | Valid Loss: 0.6174\n","output_type":"stream"},{"name":"stderr","text":"Epoch [101/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.65it/s, loss=1.5]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 101: Train Loss: 1.5832 | Valid Loss: 0.6046\n","output_type":"stream"},{"name":"stderr","text":"Epoch [102/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.77it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 102: Train Loss: 1.5640 | Valid Loss: 0.6354\n","output_type":"stream"},{"name":"stderr","text":"Epoch [103/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.54it/s, loss=1.61]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 103: Train Loss: 1.6539 | Valid Loss: 0.6211\n","output_type":"stream"},{"name":"stderr","text":"Epoch [104/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.91it/s, loss=1.62]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 104: Train Loss: 1.6693 | Valid Loss: 0.6375\n","output_type":"stream"},{"name":"stderr","text":"Epoch [105/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.58it/s, loss=1.58]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 105: Train Loss: 1.7053 | Valid Loss: 0.6485\n","output_type":"stream"},{"name":"stderr","text":"Epoch [106/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.66it/s, loss=1.72]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 106: Train Loss: 1.6277 | Valid Loss: 0.6170\n","output_type":"stream"},{"name":"stderr","text":"Epoch [107/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.21it/s, loss=1.75]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 107: Train Loss: 1.6276 | Valid Loss: 0.6118\n","output_type":"stream"},{"name":"stderr","text":"Epoch [108/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.25it/s, loss=1.72]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 108: Train Loss: 1.6207 | Valid Loss: 0.6354\n","output_type":"stream"},{"name":"stderr","text":"Epoch [109/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.21it/s, loss=1.4]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 109: Train Loss: 1.5720 | Valid Loss: 0.6476\n","output_type":"stream"},{"name":"stderr","text":"Epoch [110/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.58it/s, loss=1.68]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 110: Train Loss: 1.6485 | Valid Loss: 0.6824\n","output_type":"stream"},{"name":"stderr","text":"Epoch [111/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.02it/s, loss=1.71]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 111: Train Loss: 1.6079 | Valid Loss: 0.6994\n","output_type":"stream"},{"name":"stderr","text":"Epoch [112/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.99it/s, loss=1.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 112: Train Loss: 1.5922 | Valid Loss: 0.6467\n","output_type":"stream"},{"name":"stderr","text":"Epoch [113/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.46it/s, loss=1.59]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 113: Train Loss: 1.5895 | Valid Loss: 0.5758\n","output_type":"stream"},{"name":"stderr","text":"Epoch [114/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.32it/s, loss=1.61]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 114: Train Loss: 1.6381 | Valid Loss: 0.5805\n","output_type":"stream"},{"name":"stderr","text":"Epoch [115/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.73it/s, loss=1.72]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 115: Train Loss: 1.6348 | Valid Loss: 0.6412\n","output_type":"stream"},{"name":"stderr","text":"Epoch [116/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.14it/s, loss=1.53]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 116: Train Loss: 1.6522 | Valid Loss: 0.6048\n","output_type":"stream"},{"name":"stderr","text":"Epoch [117/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.42it/s, loss=1.54]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 117: Train Loss: 1.5893 | Valid Loss: 0.6187\n","output_type":"stream"},{"name":"stderr","text":"Epoch [118/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.07it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 118: Train Loss: 1.5482 | Valid Loss: 0.6873\n","output_type":"stream"},{"name":"stderr","text":"Epoch [119/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.35it/s, loss=1.7] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 119: Train Loss: 1.5750 | Valid Loss: 0.6959\n","output_type":"stream"},{"name":"stderr","text":"Epoch [120/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.02it/s, loss=1.62]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 120: Train Loss: 1.6183 | Valid Loss: 0.6453\n","output_type":"stream"},{"name":"stderr","text":"Epoch [121/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.03it/s, loss=1.59]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 121: Train Loss: 1.6456 | Valid Loss: 0.6229\n","output_type":"stream"},{"name":"stderr","text":"Epoch [122/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.25it/s, loss=1.58]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 122: Train Loss: 1.5921 | Valid Loss: 0.6283\n","output_type":"stream"},{"name":"stderr","text":"Epoch [123/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.79it/s, loss=1.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 123: Train Loss: 1.5913 | Valid Loss: 0.6219\n","output_type":"stream"},{"name":"stderr","text":"Epoch [124/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.19it/s, loss=1.69]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 124: Train Loss: 1.5921 | Valid Loss: 0.6587\n","output_type":"stream"},{"name":"stderr","text":"Epoch [125/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.78it/s, loss=1.67]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 125: Train Loss: 1.5664 | Valid Loss: 0.6428\n","output_type":"stream"},{"name":"stderr","text":"Epoch [126/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.75it/s, loss=1.56]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 126: Train Loss: 1.5659 | Valid Loss: 0.6206\n","output_type":"stream"},{"name":"stderr","text":"Epoch [127/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.85it/s, loss=1.79]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 127: Train Loss: 1.6601 | Valid Loss: 0.5730\n","output_type":"stream"},{"name":"stderr","text":"Epoch [128/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.89it/s, loss=1.7]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 128: Train Loss: 1.6046 | Valid Loss: 0.5733\n","output_type":"stream"},{"name":"stderr","text":"Epoch [129/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.98it/s, loss=1.64]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 129: Train Loss: 1.6153 | Valid Loss: 0.5786\n","output_type":"stream"},{"name":"stderr","text":"Epoch [130/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.89it/s, loss=1.7]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 130: Train Loss: 1.6127 | Valid Loss: 0.6053\n","output_type":"stream"},{"name":"stderr","text":"Epoch [131/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.07it/s, loss=1.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 131: Train Loss: 1.6145 | Valid Loss: 0.6488\n","output_type":"stream"},{"name":"stderr","text":"Epoch [132/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.35it/s, loss=1.68]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 132: Train Loss: 1.5688 | Valid Loss: 0.6845\n","output_type":"stream"},{"name":"stderr","text":"Epoch [133/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.49it/s, loss=1.64]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 133: Train Loss: 1.5763 | Valid Loss: 0.7245\n","output_type":"stream"},{"name":"stderr","text":"Epoch [134/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.61it/s, loss=1.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 134: Train Loss: 1.5842 | Valid Loss: 0.6900\n","output_type":"stream"},{"name":"stderr","text":"Epoch [135/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.43it/s, loss=1.68]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 135: Train Loss: 1.6003 | Valid Loss: 0.6272\n","output_type":"stream"},{"name":"stderr","text":"Epoch [136/1000]: 100%|██████████| 5/5 [00:00<00:00, 34.48it/s, loss=1.49]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 136: Train Loss: 1.6240 | Valid Loss: 0.6022\n","output_type":"stream"},{"name":"stderr","text":"Epoch [137/1000]: 100%|██████████| 5/5 [00:00<00:00, 31.48it/s, loss=1.52]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 137: Train Loss: 1.6073 | Valid Loss: 0.6091\n","output_type":"stream"},{"name":"stderr","text":"Epoch [138/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.70it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 138: Train Loss: 1.5234 | Valid Loss: 0.5831\n","output_type":"stream"},{"name":"stderr","text":"Epoch [139/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.67it/s, loss=1.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 139: Train Loss: 1.5379 | Valid Loss: 0.5762\n","output_type":"stream"},{"name":"stderr","text":"Epoch [140/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.21it/s, loss=1.42]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 140: Train Loss: 1.5700 | Valid Loss: 0.5706\n","output_type":"stream"},{"name":"stderr","text":"Epoch [141/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.88it/s, loss=1.56]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 141: Train Loss: 1.5668 | Valid Loss: 0.5550\n","output_type":"stream"},{"name":"stderr","text":"Epoch [142/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.08it/s, loss=1.77]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 142: Train Loss: 1.6111 | Valid Loss: 0.5914\n","output_type":"stream"},{"name":"stderr","text":"Epoch [143/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.79it/s, loss=1.58]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 143: Train Loss: 1.5374 | Valid Loss: 0.5937\n","output_type":"stream"},{"name":"stderr","text":"Epoch [144/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.44it/s, loss=1.54]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 144: Train Loss: 1.5568 | Valid Loss: 0.6006\n","output_type":"stream"},{"name":"stderr","text":"Epoch [145/1000]: 100%|██████████| 5/5 [00:00<00:00, 34.49it/s, loss=1.73]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 145: Train Loss: 1.7115 | Valid Loss: 0.5839\n","output_type":"stream"},{"name":"stderr","text":"Epoch [146/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.43it/s, loss=1.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 146: Train Loss: 1.5717 | Valid Loss: 0.6243\n","output_type":"stream"},{"name":"stderr","text":"Epoch [147/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.63it/s, loss=1.6]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 147: Train Loss: 1.5496 | Valid Loss: 0.6250\n","output_type":"stream"},{"name":"stderr","text":"Epoch [148/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.87it/s, loss=1.85]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 148: Train Loss: 1.5774 | Valid Loss: 0.6521\n","output_type":"stream"},{"name":"stderr","text":"Epoch [149/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.31it/s, loss=1.68]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 149: Train Loss: 1.5991 | Valid Loss: 0.6088\n","output_type":"stream"},{"name":"stderr","text":"Epoch [150/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.31it/s, loss=1.58]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 150: Train Loss: 1.5405 | Valid Loss: 0.5942\n","output_type":"stream"},{"name":"stderr","text":"Epoch [151/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.75it/s, loss=1.58]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 151: Train Loss: 1.5665 | Valid Loss: 0.5791\n","output_type":"stream"},{"name":"stderr","text":"Epoch [152/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.81it/s, loss=1.58]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 152: Train Loss: 1.5791 | Valid Loss: 0.5937\n","output_type":"stream"},{"name":"stderr","text":"Epoch [153/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.82it/s, loss=1.57]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 153: Train Loss: 1.5459 | Valid Loss: 0.5725\n","output_type":"stream"},{"name":"stderr","text":"Epoch [154/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.16it/s, loss=1.68]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 154: Train Loss: 1.5608 | Valid Loss: 0.6135\n","output_type":"stream"},{"name":"stderr","text":"Epoch [155/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.66it/s, loss=1.6]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 155: Train Loss: 1.5697 | Valid Loss: 0.6287\n","output_type":"stream"},{"name":"stderr","text":"Epoch [156/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.44it/s, loss=1.41]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 156: Train Loss: 1.5593 | Valid Loss: 0.6327\n","output_type":"stream"},{"name":"stderr","text":"Epoch [157/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.56it/s, loss=1.38]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 157: Train Loss: 1.5075 | Valid Loss: 0.6213\n","output_type":"stream"},{"name":"stderr","text":"Epoch [158/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.13it/s, loss=1.43]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 158: Train Loss: 1.5292 | Valid Loss: 0.5885\n","output_type":"stream"},{"name":"stderr","text":"Epoch [159/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.22it/s, loss=1.64]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 159: Train Loss: 1.5641 | Valid Loss: 0.5569\n","output_type":"stream"},{"name":"stderr","text":"Epoch [160/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.36it/s, loss=1.42]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 160: Train Loss: 1.5200 | Valid Loss: 0.5587\n","output_type":"stream"},{"name":"stderr","text":"Epoch [161/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.90it/s, loss=1.56]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 161: Train Loss: 1.5020 | Valid Loss: 0.5753\n","output_type":"stream"},{"name":"stderr","text":"Epoch [162/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.71it/s, loss=1.61]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 162: Train Loss: 1.5188 | Valid Loss: 0.5967\n","output_type":"stream"},{"name":"stderr","text":"Epoch [163/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.22it/s, loss=1.57]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 163: Train Loss: 1.5790 | Valid Loss: 0.5980\n","output_type":"stream"},{"name":"stderr","text":"Epoch [164/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.59it/s, loss=1.4]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 164: Train Loss: 1.4906 | Valid Loss: 0.6013\n","output_type":"stream"},{"name":"stderr","text":"Epoch [165/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.17it/s, loss=1.48]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 165: Train Loss: 1.5115 | Valid Loss: 0.5879\n","output_type":"stream"},{"name":"stderr","text":"Epoch [166/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.36it/s, loss=1.44]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 166: Train Loss: 1.5297 | Valid Loss: 0.5757\n","output_type":"stream"},{"name":"stderr","text":"Epoch [167/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.80it/s, loss=1.37]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 167: Train Loss: 1.5247 | Valid Loss: 0.5647\n","output_type":"stream"},{"name":"stderr","text":"Epoch [168/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.69it/s, loss=1.56]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 168: Train Loss: 1.5190 | Valid Loss: 0.5766\n","output_type":"stream"},{"name":"stderr","text":"Epoch [169/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.37it/s, loss=1.62]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 169: Train Loss: 1.5290 | Valid Loss: 0.6005\n","output_type":"stream"},{"name":"stderr","text":"Epoch [170/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.67it/s, loss=1.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 170: Train Loss: 1.5476 | Valid Loss: 0.6314\n","output_type":"stream"},{"name":"stderr","text":"Epoch [171/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.32it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 171: Train Loss: 1.5580 | Valid Loss: 0.6017\n","output_type":"stream"},{"name":"stderr","text":"Epoch [172/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.43it/s, loss=1.57]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 172: Train Loss: 1.5360 | Valid Loss: 0.6089\n","output_type":"stream"},{"name":"stderr","text":"Epoch [173/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.17it/s, loss=1.52]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 173: Train Loss: 1.5099 | Valid Loss: 0.6088\n","output_type":"stream"},{"name":"stderr","text":"Epoch [174/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.16it/s, loss=1.45]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 174: Train Loss: 1.5525 | Valid Loss: 0.6039\n","output_type":"stream"},{"name":"stderr","text":"Epoch [175/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.83it/s, loss=1.67]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 175: Train Loss: 1.4954 | Valid Loss: 0.6279\n","output_type":"stream"},{"name":"stderr","text":"Epoch [176/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.24it/s, loss=1.65]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 176: Train Loss: 1.5799 | Valid Loss: 0.5893\n","output_type":"stream"},{"name":"stderr","text":"Epoch [177/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.92it/s, loss=1.43]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 177: Train Loss: 1.5015 | Valid Loss: 0.5695\n","output_type":"stream"},{"name":"stderr","text":"Epoch [178/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.16it/s, loss=1.62]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 178: Train Loss: 1.5061 | Valid Loss: 0.5833\n","output_type":"stream"},{"name":"stderr","text":"Epoch [179/1000]: 100%|██████████| 5/5 [00:00<00:00, 33.79it/s, loss=1.74]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 179: Train Loss: 1.5330 | Valid Loss: 0.6017\n","output_type":"stream"},{"name":"stderr","text":"Epoch [180/1000]: 100%|██████████| 5/5 [00:00<00:00, 31.33it/s, loss=1.52]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 180: Train Loss: 1.5504 | Valid Loss: 0.5725\n","output_type":"stream"},{"name":"stderr","text":"Epoch [181/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.94it/s, loss=1.5]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 181: Train Loss: 1.5134 | Valid Loss: 0.5769\n","output_type":"stream"},{"name":"stderr","text":"Epoch [182/1000]: 100%|██████████| 5/5 [00:00<00:00, 32.69it/s, loss=1.42]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 182: Train Loss: 1.4476 | Valid Loss: 0.5563\n","output_type":"stream"},{"name":"stderr","text":"Epoch [183/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.78it/s, loss=1.46]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 183: Train Loss: 1.5310 | Valid Loss: 0.5630\n","output_type":"stream"},{"name":"stderr","text":"Epoch [184/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.19it/s, loss=1.47]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 184: Train Loss: 1.5742 | Valid Loss: 0.5757\n","output_type":"stream"},{"name":"stderr","text":"Epoch [185/1000]: 100%|██████████| 5/5 [00:00<00:00, 33.52it/s, loss=1.65]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 185: Train Loss: 1.5133 | Valid Loss: 0.5729\n","output_type":"stream"},{"name":"stderr","text":"Epoch [186/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.51it/s, loss=1.41]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 186: Train Loss: 1.5287 | Valid Loss: 0.5655\n","output_type":"stream"},{"name":"stderr","text":"Epoch [187/1000]: 100%|██████████| 5/5 [00:00<00:00, 31.05it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 187: Train Loss: 1.5207 | Valid Loss: 0.5764\n","output_type":"stream"},{"name":"stderr","text":"Epoch [188/1000]: 100%|██████████| 5/5 [00:00<00:00, 30.82it/s, loss=1.4] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 188: Train Loss: 1.4844 | Valid Loss: 0.5987\n","output_type":"stream"},{"name":"stderr","text":"Epoch [189/1000]: 100%|██████████| 5/5 [00:00<00:00, 31.10it/s, loss=1.43]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 189: Train Loss: 1.5095 | Valid Loss: 0.6076\n","output_type":"stream"},{"name":"stderr","text":"Epoch [190/1000]: 100%|██████████| 5/5 [00:00<00:00, 30.08it/s, loss=1.44]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 190: Train Loss: 1.4869 | Valid Loss: 0.6267\n","output_type":"stream"},{"name":"stderr","text":"Epoch [191/1000]: 100%|██████████| 5/5 [00:00<00:00, 31.31it/s, loss=1.59]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 191: Train Loss: 1.5026 | Valid Loss: 0.6447\n","output_type":"stream"},{"name":"stderr","text":"Epoch [192/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.47it/s, loss=1.54]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 192: Train Loss: 1.5257 | Valid Loss: 0.6468\n","output_type":"stream"},{"name":"stderr","text":"Epoch [193/1000]: 100%|██████████| 5/5 [00:00<00:00, 33.00it/s, loss=1.62]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 193: Train Loss: 1.5134 | Valid Loss: 0.6231\n","output_type":"stream"},{"name":"stderr","text":"Epoch [194/1000]: 100%|██████████| 5/5 [00:00<00:00, 32.60it/s, loss=1.45]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 194: Train Loss: 1.4827 | Valid Loss: 0.5764\n","output_type":"stream"},{"name":"stderr","text":"Epoch [195/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.09it/s, loss=1.3]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 195: Train Loss: 1.5097 | Valid Loss: 0.5651\n","output_type":"stream"},{"name":"stderr","text":"Epoch [196/1000]: 100%|██████████| 5/5 [00:00<00:00, 33.33it/s, loss=1.5] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 196: Train Loss: 1.4869 | Valid Loss: 0.5800\n","output_type":"stream"},{"name":"stderr","text":"Epoch [197/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.78it/s, loss=1.43]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 197: Train Loss: 1.4932 | Valid Loss: 0.5848\n","output_type":"stream"},{"name":"stderr","text":"Epoch [198/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.06it/s, loss=1.4]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 198: Train Loss: 1.4938 | Valid Loss: 0.5967\n","output_type":"stream"},{"name":"stderr","text":"Epoch [199/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.70it/s, loss=1.72]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 199: Train Loss: 1.5134 | Valid Loss: 0.6108\n","output_type":"stream"},{"name":"stderr","text":"Epoch [200/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.16it/s, loss=1.44]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 200: Train Loss: 1.5133 | Valid Loss: 0.5912\n","output_type":"stream"},{"name":"stderr","text":"Epoch [201/1000]: 100%|██████████| 5/5 [00:00<00:00, 32.24it/s, loss=1.38]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 201: Train Loss: 1.5017 | Valid Loss: 0.6093\n","output_type":"stream"},{"name":"stderr","text":"Epoch [202/1000]: 100%|██████████| 5/5 [00:00<00:00, 30.31it/s, loss=1.5] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 202: Train Loss: 1.4550 | Valid Loss: 0.6176\n","output_type":"stream"},{"name":"stderr","text":"Epoch [203/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.71it/s, loss=1.57]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 203: Train Loss: 1.5218 | Valid Loss: 0.6185\n","output_type":"stream"},{"name":"stderr","text":"Epoch [204/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.55it/s, loss=1.42]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 204: Train Loss: 1.5198 | Valid Loss: 0.5840\n","output_type":"stream"},{"name":"stderr","text":"Epoch [205/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.69it/s, loss=1.44]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 205: Train Loss: 1.5194 | Valid Loss: 0.5665\n","output_type":"stream"},{"name":"stderr","text":"Epoch [206/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.42it/s, loss=1.41]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 206: Train Loss: 1.4936 | Valid Loss: 0.5850\n","output_type":"stream"},{"name":"stderr","text":"Epoch [207/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.11it/s, loss=1.56]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 207: Train Loss: 1.5162 | Valid Loss: 0.5797\n","output_type":"stream"},{"name":"stderr","text":"Epoch [208/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.35it/s, loss=1.47]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 208: Train Loss: 1.5508 | Valid Loss: 0.5810\n","output_type":"stream"},{"name":"stderr","text":"Epoch [209/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.57it/s, loss=1.52]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 209: Train Loss: 1.4607 | Valid Loss: 0.6064\n","output_type":"stream"},{"name":"stderr","text":"Epoch [210/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.71it/s, loss=1.73]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 210: Train Loss: 1.5404 | Valid Loss: 0.6184\n","output_type":"stream"},{"name":"stderr","text":"Epoch [211/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.61it/s, loss=1.78]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 211: Train Loss: 1.5722 | Valid Loss: 0.6306\n","output_type":"stream"},{"name":"stderr","text":"Epoch [212/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.31it/s, loss=1.56]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 212: Train Loss: 1.5398 | Valid Loss: 0.6225\n","output_type":"stream"},{"name":"stderr","text":"Epoch [213/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.83it/s, loss=1.49]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 213: Train Loss: 1.5055 | Valid Loss: 0.6198\n","output_type":"stream"},{"name":"stderr","text":"Epoch [214/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.57it/s, loss=1.62]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 214: Train Loss: 1.5657 | Valid Loss: 0.6114\n","output_type":"stream"},{"name":"stderr","text":"Epoch [215/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.35it/s, loss=1.54]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 215: Train Loss: 1.5181 | Valid Loss: 0.6176\n","output_type":"stream"},{"name":"stderr","text":"Epoch [216/1000]: 100%|██████████| 5/5 [00:00<00:00, 33.97it/s, loss=1.67]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 216: Train Loss: 1.5382 | Valid Loss: 0.6194\n","output_type":"stream"},{"name":"stderr","text":"Epoch [217/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.50it/s, loss=1.53]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 217: Train Loss: 1.5225 | Valid Loss: 0.6171\n","output_type":"stream"},{"name":"stderr","text":"Epoch [218/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.39it/s, loss=1.52]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 218: Train Loss: 1.5604 | Valid Loss: 0.5888\n","output_type":"stream"},{"name":"stderr","text":"Epoch [219/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.49it/s, loss=1.47]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 219: Train Loss: 1.4895 | Valid Loss: 0.5882\n","output_type":"stream"},{"name":"stderr","text":"Epoch [220/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.97it/s, loss=1.56]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 220: Train Loss: 1.5630 | Valid Loss: 0.5919\n","output_type":"stream"},{"name":"stderr","text":"Epoch [221/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.02it/s, loss=1.5]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 221: Train Loss: 1.4899 | Valid Loss: 0.5816\n","output_type":"stream"},{"name":"stderr","text":"Epoch [222/1000]: 100%|██████████| 5/5 [00:00<00:00, 34.99it/s, loss=1.7] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 222: Train Loss: 1.5150 | Valid Loss: 0.5971\n","output_type":"stream"},{"name":"stderr","text":"Epoch [223/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.68it/s, loss=1.5]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 223: Train Loss: 1.5355 | Valid Loss: 0.5847\n","output_type":"stream"},{"name":"stderr","text":"Epoch [224/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.42it/s, loss=1.61]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 224: Train Loss: 1.4974 | Valid Loss: 0.5949\n","output_type":"stream"},{"name":"stderr","text":"Epoch [225/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.68it/s, loss=1.47]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 225: Train Loss: 1.5612 | Valid Loss: 0.5488\n","output_type":"stream"},{"name":"stderr","text":"Epoch [226/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.22it/s, loss=1.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 226: Train Loss: 1.5040 | Valid Loss: 0.5552\n","output_type":"stream"},{"name":"stderr","text":"Epoch [227/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.63it/s, loss=1.44]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 227: Train Loss: 1.5806 | Valid Loss: 0.5611\n","output_type":"stream"},{"name":"stderr","text":"Epoch [228/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.20it/s, loss=1.61]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 228: Train Loss: 1.5450 | Valid Loss: 0.5720\n","output_type":"stream"},{"name":"stderr","text":"Epoch [229/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.07it/s, loss=1.4]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 229: Train Loss: 1.4937 | Valid Loss: 0.5786\n","output_type":"stream"},{"name":"stderr","text":"Epoch [230/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.63it/s, loss=1.95]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 230: Train Loss: 1.5406 | Valid Loss: 0.6184\n","output_type":"stream"},{"name":"stderr","text":"Epoch [231/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.44it/s, loss=1.81]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 231: Train Loss: 1.6021 | Valid Loss: 0.6249\n","output_type":"stream"},{"name":"stderr","text":"Epoch [232/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.35it/s, loss=1.39]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 232: Train Loss: 1.4806 | Valid Loss: 0.6072\n","output_type":"stream"},{"name":"stderr","text":"Epoch [233/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.64it/s, loss=1.36]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 233: Train Loss: 1.4973 | Valid Loss: 0.6041\n","output_type":"stream"},{"name":"stderr","text":"Epoch [234/1000]: 100%|██████████| 5/5 [00:00<00:00, 34.93it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 234: Train Loss: 1.5309 | Valid Loss: 0.5928\n","output_type":"stream"},{"name":"stderr","text":"Epoch [235/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.37it/s, loss=1.5]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 235: Train Loss: 1.4825 | Valid Loss: 0.5738\n","output_type":"stream"},{"name":"stderr","text":"Epoch [236/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.48it/s, loss=1.45]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 236: Train Loss: 1.5000 | Valid Loss: 0.5953\n","output_type":"stream"},{"name":"stderr","text":"Epoch [237/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.11it/s, loss=1.57]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 237: Train Loss: 1.5832 | Valid Loss: 0.5635\n","output_type":"stream"},{"name":"stderr","text":"Epoch [238/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.06it/s, loss=1.6]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 238: Train Loss: 1.5135 | Valid Loss: 0.5933\n","output_type":"stream"},{"name":"stderr","text":"Epoch [239/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.24it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 239: Train Loss: 1.5021 | Valid Loss: 0.5879\n","output_type":"stream"},{"name":"stderr","text":"Epoch [240/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.51it/s, loss=1.46]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 240: Train Loss: 1.5256 | Valid Loss: 0.5842\n","output_type":"stream"},{"name":"stderr","text":"Epoch [241/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.03it/s, loss=1.76]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 241: Train Loss: 1.5774 | Valid Loss: 0.6041\n","output_type":"stream"},{"name":"stderr","text":"Epoch [242/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.94it/s, loss=1.53]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 242: Train Loss: 1.4932 | Valid Loss: 0.5976\n","output_type":"stream"},{"name":"stderr","text":"Epoch [243/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.73it/s, loss=1.59]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 243: Train Loss: 1.5398 | Valid Loss: 0.5839\n","output_type":"stream"},{"name":"stderr","text":"Epoch [244/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.82it/s, loss=1.49]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 244: Train Loss: 1.5037 | Valid Loss: 0.5740\n","output_type":"stream"},{"name":"stderr","text":"Epoch [245/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.73it/s, loss=1.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 245: Train Loss: 1.5671 | Valid Loss: 0.5758\n","output_type":"stream"},{"name":"stderr","text":"Epoch [246/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.44it/s, loss=1.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 246: Train Loss: 1.5467 | Valid Loss: 0.6047\n","output_type":"stream"},{"name":"stderr","text":"Epoch [247/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.17it/s, loss=1.88]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 247: Train Loss: 1.5835 | Valid Loss: 0.6217\n","output_type":"stream"},{"name":"stderr","text":"Epoch [248/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.12it/s, loss=1.45]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 248: Train Loss: 1.4574 | Valid Loss: 0.5899\n","output_type":"stream"},{"name":"stderr","text":"Epoch [249/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.27it/s, loss=1.46]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 249: Train Loss: 1.4582 | Valid Loss: 0.5883\n","output_type":"stream"},{"name":"stderr","text":"Epoch [250/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.64it/s, loss=1.43]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 250: Train Loss: 1.4932 | Valid Loss: 0.5930\n","output_type":"stream"},{"name":"stderr","text":"Epoch [251/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.98it/s, loss=1.4]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 251: Train Loss: 1.5095 | Valid Loss: 0.5848\n","output_type":"stream"},{"name":"stderr","text":"Epoch [252/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.80it/s, loss=1.4] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 252: Train Loss: 1.4881 | Valid Loss: 0.5806\n","output_type":"stream"},{"name":"stderr","text":"Epoch [253/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.78it/s, loss=1.54]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 253: Train Loss: 1.5387 | Valid Loss: 0.5785\n","output_type":"stream"},{"name":"stderr","text":"Epoch [254/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.54it/s, loss=1.47]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 254: Train Loss: 1.4436 | Valid Loss: 0.5812\n","output_type":"stream"},{"name":"stderr","text":"Epoch [255/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.94it/s, loss=1.58]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 255: Train Loss: 1.5242 | Valid Loss: 0.5771\n","output_type":"stream"},{"name":"stderr","text":"Epoch [256/1000]: 100%|██████████| 5/5 [00:00<00:00, 32.92it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 256: Train Loss: 1.4777 | Valid Loss: 0.5839\n","output_type":"stream"},{"name":"stderr","text":"Epoch [257/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.21it/s, loss=1.64]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 257: Train Loss: 1.4805 | Valid Loss: 0.5901\n","output_type":"stream"},{"name":"stderr","text":"Epoch [258/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.33it/s, loss=1.39]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 258: Train Loss: 1.5104 | Valid Loss: 0.5741\n","output_type":"stream"},{"name":"stderr","text":"Epoch [259/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.34it/s, loss=1.61]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 259: Train Loss: 1.5358 | Valid Loss: 0.5770\n","output_type":"stream"},{"name":"stderr","text":"Epoch [260/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.65it/s, loss=1.56]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 260: Train Loss: 1.5756 | Valid Loss: 0.5835\n","output_type":"stream"},{"name":"stderr","text":"Epoch [261/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.63it/s, loss=1.5] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 261: Train Loss: 1.5341 | Valid Loss: 0.5653\n","output_type":"stream"},{"name":"stderr","text":"Epoch [262/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.26it/s, loss=1.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 262: Train Loss: 1.5327 | Valid Loss: 0.5844\n","output_type":"stream"},{"name":"stderr","text":"Epoch [263/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.92it/s, loss=1.66]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 263: Train Loss: 1.5229 | Valid Loss: 0.5972\n","output_type":"stream"},{"name":"stderr","text":"Epoch [264/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.61it/s, loss=1.57]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 264: Train Loss: 1.5016 | Valid Loss: 0.5851\n","output_type":"stream"},{"name":"stderr","text":"Epoch [265/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.30it/s, loss=1.39]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 265: Train Loss: 1.5051 | Valid Loss: 0.5854\n","output_type":"stream"},{"name":"stderr","text":"Epoch [266/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.88it/s, loss=1.41]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 266: Train Loss: 1.4886 | Valid Loss: 0.5830\n","output_type":"stream"},{"name":"stderr","text":"Epoch [267/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.44it/s, loss=1.66]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 267: Train Loss: 1.5348 | Valid Loss: 0.5971\n","output_type":"stream"},{"name":"stderr","text":"Epoch [268/1000]: 100%|██████████| 5/5 [00:00<00:00, 31.10it/s, loss=1.45]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 268: Train Loss: 1.5224 | Valid Loss: 0.5772\n","output_type":"stream"},{"name":"stderr","text":"Epoch [269/1000]: 100%|██████████| 5/5 [00:00<00:00, 28.95it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 269: Train Loss: 1.5061 | Valid Loss: 0.5706\n","output_type":"stream"},{"name":"stderr","text":"Epoch [270/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.99it/s, loss=1.49]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 270: Train Loss: 1.5089 | Valid Loss: 0.5604\n","output_type":"stream"},{"name":"stderr","text":"Epoch [271/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.65it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 271: Train Loss: 1.5580 | Valid Loss: 0.5704\n","output_type":"stream"},{"name":"stderr","text":"Epoch [272/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.96it/s, loss=1.42]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 272: Train Loss: 1.4480 | Valid Loss: 0.5782\n","output_type":"stream"},{"name":"stderr","text":"Epoch [273/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.94it/s, loss=1.68]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 273: Train Loss: 1.5277 | Valid Loss: 0.5787\n","output_type":"stream"},{"name":"stderr","text":"Epoch [274/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.95it/s, loss=1.6]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 274: Train Loss: 1.5114 | Valid Loss: 0.5667\n","output_type":"stream"},{"name":"stderr","text":"Epoch [275/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.73it/s, loss=1.36]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 275: Train Loss: 1.4667 | Valid Loss: 0.5739\n","output_type":"stream"},{"name":"stderr","text":"Epoch [276/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.17it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 276: Train Loss: 1.4976 | Valid Loss: 0.5724\n","output_type":"stream"},{"name":"stderr","text":"Epoch [277/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.62it/s, loss=1.68]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 277: Train Loss: 1.5528 | Valid Loss: 0.5689\n","output_type":"stream"},{"name":"stderr","text":"Epoch [278/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.01it/s, loss=1.66]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 278: Train Loss: 1.5071 | Valid Loss: 0.5826\n","output_type":"stream"},{"name":"stderr","text":"Epoch [279/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.35it/s, loss=1.56]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 279: Train Loss: 1.4711 | Valid Loss: 0.5852\n","output_type":"stream"},{"name":"stderr","text":"Epoch [280/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.92it/s, loss=1.57]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 280: Train Loss: 1.4893 | Valid Loss: 0.5866\n","output_type":"stream"},{"name":"stderr","text":"Epoch [281/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.94it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 281: Train Loss: 1.5157 | Valid Loss: 0.5674\n","output_type":"stream"},{"name":"stderr","text":"Epoch [282/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.62it/s, loss=1.39]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 282: Train Loss: 1.4477 | Valid Loss: 0.5756\n","output_type":"stream"},{"name":"stderr","text":"Epoch [283/1000]: 100%|██████████| 5/5 [00:00<00:00, 41.55it/s, loss=1.36]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 283: Train Loss: 1.4812 | Valid Loss: 0.5839\n","output_type":"stream"},{"name":"stderr","text":"Epoch [284/1000]: 100%|██████████| 5/5 [00:00<00:00, 34.89it/s, loss=1.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 284: Train Loss: 1.4943 | Valid Loss: 0.6001\n","output_type":"stream"},{"name":"stderr","text":"Epoch [285/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.71it/s, loss=1.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 285: Train Loss: 1.4727 | Valid Loss: 0.5988\n","output_type":"stream"},{"name":"stderr","text":"Epoch [286/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.49it/s, loss=1.48]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 286: Train Loss: 1.5073 | Valid Loss: 0.5968\n","output_type":"stream"},{"name":"stderr","text":"Epoch [287/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.99it/s, loss=1.51]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 287: Train Loss: 1.5159 | Valid Loss: 0.5909\n","output_type":"stream"},{"name":"stderr","text":"Epoch [288/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.59it/s, loss=1.35]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 288: Train Loss: 1.5179 | Valid Loss: 0.5897\n","output_type":"stream"},{"name":"stderr","text":"Epoch [289/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.99it/s, loss=1.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 289: Train Loss: 1.5171 | Valid Loss: 0.5736\n","output_type":"stream"},{"name":"stderr","text":"Epoch [290/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.53it/s, loss=1.46]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 290: Train Loss: 1.5367 | Valid Loss: 0.5603\n","output_type":"stream"},{"name":"stderr","text":"Epoch [291/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.44it/s, loss=1.39]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 291: Train Loss: 1.5201 | Valid Loss: 0.5916\n","output_type":"stream"},{"name":"stderr","text":"Epoch [292/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.22it/s, loss=1.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 292: Train Loss: 1.5087 | Valid Loss: 0.6100\n","output_type":"stream"},{"name":"stderr","text":"Epoch [293/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.22it/s, loss=1.73]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 293: Train Loss: 1.5413 | Valid Loss: 0.6161\n","output_type":"stream"},{"name":"stderr","text":"Epoch [294/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.97it/s, loss=1.81]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 294: Train Loss: 1.5380 | Valid Loss: 0.6236\n","output_type":"stream"},{"name":"stderr","text":"Epoch [295/1000]: 100%|██████████| 5/5 [00:00<00:00, 34.35it/s, loss=1.58]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 295: Train Loss: 1.4881 | Valid Loss: 0.6166\n","output_type":"stream"},{"name":"stderr","text":"Epoch [296/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.73it/s, loss=1.5]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 296: Train Loss: 1.4941 | Valid Loss: 0.6000\n","output_type":"stream"},{"name":"stderr","text":"Epoch [297/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.89it/s, loss=1.36]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 297: Train Loss: 1.4972 | Valid Loss: 0.5892\n","output_type":"stream"},{"name":"stderr","text":"Epoch [298/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.59it/s, loss=1.49]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 298: Train Loss: 1.4754 | Valid Loss: 0.5919\n","output_type":"stream"},{"name":"stderr","text":"Epoch [299/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.22it/s, loss=1.61]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 299: Train Loss: 1.5674 | Valid Loss: 0.5715\n","output_type":"stream"},{"name":"stderr","text":"Epoch [300/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.25it/s, loss=1.47]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 300: Train Loss: 1.5073 | Valid Loss: 0.5673\n","output_type":"stream"},{"name":"stderr","text":"Epoch [301/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.19it/s, loss=1.46]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 301: Train Loss: 1.5257 | Valid Loss: 0.5678\n","output_type":"stream"},{"name":"stderr","text":"Epoch [302/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.74it/s, loss=1.41]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 302: Train Loss: 1.5274 | Valid Loss: 0.5709\n","output_type":"stream"},{"name":"stderr","text":"Epoch [303/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.36it/s, loss=1.45]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 303: Train Loss: 1.4883 | Valid Loss: 0.5835\n","output_type":"stream"},{"name":"stderr","text":"Epoch [304/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.12it/s, loss=1.62]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 304: Train Loss: 1.5080 | Valid Loss: 0.5864\n","output_type":"stream"},{"name":"stderr","text":"Epoch [305/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.52it/s, loss=1.58]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 305: Train Loss: 1.5467 | Valid Loss: 0.5671\n","output_type":"stream"},{"name":"stderr","text":"Epoch [306/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.16it/s, loss=1.49]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 306: Train Loss: 1.4851 | Valid Loss: 0.5778\n","output_type":"stream"},{"name":"stderr","text":"Epoch [307/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.52it/s, loss=1.71]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 307: Train Loss: 1.5738 | Valid Loss: 0.5926\n","output_type":"stream"},{"name":"stderr","text":"Epoch [308/1000]: 100%|██████████| 5/5 [00:00<00:00, 38.00it/s, loss=1.46]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 308: Train Loss: 1.4467 | Valid Loss: 0.5628\n","output_type":"stream"},{"name":"stderr","text":"Epoch [309/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.36it/s, loss=1.42]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 309: Train Loss: 1.5001 | Valid Loss: 0.5727\n","output_type":"stream"},{"name":"stderr","text":"Epoch [310/1000]: 100%|██████████| 5/5 [00:00<00:00, 34.71it/s, loss=1.5] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 310: Train Loss: 1.5171 | Valid Loss: 0.5726\n","output_type":"stream"},{"name":"stderr","text":"Epoch [311/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.43it/s, loss=1.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 311: Train Loss: 1.4847 | Valid Loss: 0.5885\n","output_type":"stream"},{"name":"stderr","text":"Epoch [312/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.00it/s, loss=1.48]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 312: Train Loss: 1.4386 | Valid Loss: 0.5997\n","output_type":"stream"},{"name":"stderr","text":"Epoch [313/1000]: 100%|██████████| 5/5 [00:00<00:00, 35.14it/s, loss=1.53]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 313: Train Loss: 1.4971 | Valid Loss: 0.6003\n","output_type":"stream"},{"name":"stderr","text":"Epoch [314/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.58it/s, loss=1.53]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 314: Train Loss: 1.5187 | Valid Loss: 0.5779\n","output_type":"stream"},{"name":"stderr","text":"Epoch [315/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.80it/s, loss=1.46]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 315: Train Loss: 1.5298 | Valid Loss: 0.5767\n","output_type":"stream"},{"name":"stderr","text":"Epoch [316/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.45it/s, loss=1.54]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 316: Train Loss: 1.5390 | Valid Loss: 0.5640\n","output_type":"stream"},{"name":"stderr","text":"Epoch [317/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.71it/s, loss=1.44]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 317: Train Loss: 1.5195 | Valid Loss: 0.5734\n","output_type":"stream"},{"name":"stderr","text":"Epoch [318/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.99it/s, loss=1.46]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 318: Train Loss: 1.5656 | Valid Loss: 0.5701\n","output_type":"stream"},{"name":"stderr","text":"Epoch [319/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.28it/s, loss=1.47]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 319: Train Loss: 1.4972 | Valid Loss: 0.5913\n","output_type":"stream"},{"name":"stderr","text":"Epoch [320/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.15it/s, loss=1.42]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 320: Train Loss: 1.4807 | Valid Loss: 0.5804\n","output_type":"stream"},{"name":"stderr","text":"Epoch [321/1000]: 100%|██████████| 5/5 [00:00<00:00, 37.26it/s, loss=1.42]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 321: Train Loss: 1.4687 | Valid Loss: 0.5649\n","output_type":"stream"},{"name":"stderr","text":"Epoch [322/1000]: 100%|██████████| 5/5 [00:00<00:00, 36.04it/s, loss=1.69]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 322: Train Loss: 1.4969 | Valid Loss: 0.5765\n","output_type":"stream"},{"name":"stderr","text":"Epoch [323/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.11it/s, loss=1.66]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 323: Train Loss: 1.5181 | Valid Loss: 0.5816\n","output_type":"stream"},{"name":"stderr","text":"Epoch [324/1000]: 100%|██████████| 5/5 [00:00<00:00, 39.55it/s, loss=1.5]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 324: Train Loss: 1.5084 | Valid Loss: 0.5889\n","output_type":"stream"},{"name":"stderr","text":"Epoch [325/1000]: 100%|██████████| 5/5 [00:00<00:00, 40.20it/s, loss=1.52]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 325: Train Loss: 1.5546 | Valid Loss: 0.5978\n\nEarly stopping at epoch 325\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2/2 [00:00<00:00, 193.29it/s]\n","output_type":"stream"}],"execution_count":77}]}