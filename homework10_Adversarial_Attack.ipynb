{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Adversarial Attack\n\n## Example of Attack\n## 加入杂讯的照片Attacked Image 和Benign Image输入到Network只差了一点点,杂讯是人肉眼无法看出的\n## Non-targeted:Anything other than \"Cat\"\n## Targeted:Misclassified as a specific class(e.g.,\"Star Fish\")\n## Network = ResNet-50\n## 加入杂讯后可以变成任何想要的target,比如那个猫辨认成狗那个hhh\n## 如果杂讯是人肉眼可见的,那还是有依据的.如果人肉眼看不出来十分微小的咨询,那就天差地别了\n## 前提x和x^0的差距极小.not perceived by humans\n## 1.L2-norm计算距离的平方 2.计算L-infinity:把每一个维度取绝对值然后找出最大值作为距离  无论是1还是2都要考虑到人类的感知距离\n## Change every pixel a little bit 和 Change one pixel much的L2是一样的,L-infinity是不一样的  Change one pixel much的L2很大.L-infinity是最接近人类的感知的更符合人类的需求.所以L-infinity才是限制条件\n## Non-targeted:L(x) = -e(y,y^)越小越好,即y和y^越大\n## Targeted:L(x) = -e(y,y^) + e(y,y^target)\n\n## Gradient Descent  只不过Update input, not parameters\n## 从x0开始 For t = 1 to T 计算Gradient 计算x对loss的偏微分 Update image if d(x0,t) > 很小的值 fix(xt)->xt\n\n## Fast Gradient Sign Method(FGSM)\n## 只Update一次参数,取sign只能取1 or -1,最后只能落在那个小方框的四个角落上 只能过simple baseline  多跑几个iteration就能过medium baseline了Iterative FGSM\n\n## 上面都是White Box(In the previous attack,we know the network parameters)\n## 白箱攻击如果是对应的模型是百分百错误.\n## 不知道模型参数下的攻击叫Black Box Attack.\n\n# Black Box Attack\n## 假设我们知道Training Data.我们可以训练一个Proxy Network来模仿要攻击的对象.作业里也是这样的.\n## 如果不知道training data ? 可以把一堆图片丢进去,然后看输出什么.把输入输出的成对资料拿去训练一个模型.就有可能产生一个Proxy Network\n\n## Ensemble Attack\n## 找到一个Network骗过其他的Network,那么也很容易骗过对应的Network\n\n# 为什么这么容易被攻击?\n## 原因是Data而不是Model.Features决定了机器学到的结论.(从一篇paper上面得到的结论)\n\n## One pixel attack:只动图片中的一个pixel(像素).有的错的还是很有道理的.\n## Universal Adversarial Attack: 用一个signal攻击所有的图片.之前都是客制化的.有一篇论文说明是有可能成功的.\n\n## Beyond Images:Speech processing:Detect synthesized speech  Natural language processing\n\n## Attack in the Physical World\n## 1.其实真实世界里面需要考虑各种各样的角度,而不是一个固定的角度.Universal Attack是有可能成功的. 2.摄像头的解析度是有限的 3.是否真的能被做出来? 有一些颜色在物理世界和计算机的世界里是不一样的\n\n## Adversarial Reprogramming:寄生在某一个模型上.在图片外围加一些杂序然后丢入模型，这个模型就不会做原来的事情.\n\n## \"Backdoor\" in Model:Attack happens at the training phase.(模型开了一个后门,在测试的时候就会辨识错误)\n## Training data里面的图片和标注都是正常的,但是图片被attacked了\n## be careful of unknown dataset! \n\n# Defense \n## Passive Defense:在模型面前加一个Filter(e.g. Smoothing模糊化)因为某一个方向上某一种信号才能攻击成功.But,Confidence的分数会下降.所以模糊化不能太过头\n## Image Compression(压缩再解压缩)    Generator(重新产生),有办法控制Generator的输出,因为杂讯没有见过,所以无法复现,就没了\n## 模糊化实际上就是底层第一步,如果别人知道,就可以很容易地躲过去.\n## Randomization:自己都不知道怎么变的.但是Universal Attack是有可能的.(各种变化方式都知道了)\n\n## Proactive Defense\n## Adversarial Training,一种Data Augmentation的方式.没有人攻击的时候也可以用这种方式来训练,避免overfitting,让模型robust的能力变得更好.并且这个process是可以反复做多次的.\n## 在训练的阶段就进行攻击,用训练资料制造一些signal让图片具有攻击性,再把这些攻击的image标上正确的label,有了新的training data.用原来的和新的training data再重新训练模型,其实本质上就是Data Augmentation\n## 但实际上用一种new algorithm也可能攻破Adversarial Training\n## 有一些做法如Adversarial Training for Free 不使用额外的计算也可以达到相同的目标","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}