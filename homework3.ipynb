{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget -O food11.zip https://www.dropbox.com/s/up5q1gthsz3v0dq/food-11.zip?dl=0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:38:09.277004Z","iopub.execute_input":"2025-06-24T06:38:09.277830Z","iopub.status.idle":"2025-06-24T06:38:24.566980Z","shell.execute_reply.started":"2025-06-24T06:38:09.277796Z","shell.execute_reply":"2025-06-24T06:38:24.565993Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"--2025-06-24 06:38:09--  https://www.dropbox.com/s/up5q1gthsz3v0dq/food-11.zip?dl=0\nResolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://www.dropbox.com/scl/fi/w5r49vs5e956w6c4z6ob9/food-11.zip?rlkey=3no5l2xjiqgk2ckwbewaanm5p&dl=0 [following]\n--2025-06-24 06:38:09--  https://www.dropbox.com/scl/fi/w5r49vs5e956w6c4z6ob9/food-11.zip?rlkey=3no5l2xjiqgk2ckwbewaanm5p&dl=0\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://uc63e782d7b0d99570614d32615c.dl.dropboxusercontent.com/cd/0/inline/CsN7oWfj1NVl7zta8gTpLrUV7VgRvhDUjQZFlLzf5vldvh4l_X5DZk74whGohYgaOw5G2GsbXyKrJ75XA8X5oKkHCWD9hmLNucajaVme2ZRN7ECLzvx868JAXccZdGYuxPkeNvzDCLB5pi6x-JpLwqq0/file# [following]\n--2025-06-24 06:38:09--  https://uc63e782d7b0d99570614d32615c.dl.dropboxusercontent.com/cd/0/inline/CsN7oWfj1NVl7zta8gTpLrUV7VgRvhDUjQZFlLzf5vldvh4l_X5DZk74whGohYgaOw5G2GsbXyKrJ75XA8X5oKkHCWD9hmLNucajaVme2ZRN7ECLzvx868JAXccZdGYuxPkeNvzDCLB5pi6x-JpLwqq0/file\nResolving uc63e782d7b0d99570614d32615c.dl.dropboxusercontent.com (uc63e782d7b0d99570614d32615c.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\nConnecting to uc63e782d7b0d99570614d32615c.dl.dropboxusercontent.com (uc63e782d7b0d99570614d32615c.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: /cd/0/inline2/CsOurx-MqwE-sRgztbquFaZj4HL4Z-ePn6lV2Ux1uI3rsqDpiW8Y3gVUyWK5pJa4XSzlDGeKnBM9vsflKwW1JuiezdlGFcQ4wwHwLGiJncEDl6ib8nhBnzaEPaB0FE0KNKTaoeoQeugreHIqpws4m9UJWxTpnLMhbnUwgknHO6KOB6btvEo1x9hlCpNNxgm8-ChQO1oWpw80eesm_adFIPv4vSa9pPn9WWI6dgKBvr5YkSypT06OjQSQVIOjil2xTJPDYjGrhZTOHkoiuPFJRp_zhhsqfoIOkqzIRZnVETkubEZMWMknT1GYHDkx0CZk12P1ZaknVJJdgX3MYjDReQvX2Jdwrr4pqZttou3Hg5_HroJMagbLuO9q3MQ1WMQj7OQ/file [following]\n--2025-06-24 06:38:10--  https://uc63e782d7b0d99570614d32615c.dl.dropboxusercontent.com/cd/0/inline2/CsOurx-MqwE-sRgztbquFaZj4HL4Z-ePn6lV2Ux1uI3rsqDpiW8Y3gVUyWK5pJa4XSzlDGeKnBM9vsflKwW1JuiezdlGFcQ4wwHwLGiJncEDl6ib8nhBnzaEPaB0FE0KNKTaoeoQeugreHIqpws4m9UJWxTpnLMhbnUwgknHO6KOB6btvEo1x9hlCpNNxgm8-ChQO1oWpw80eesm_adFIPv4vSa9pPn9WWI6dgKBvr5YkSypT06OjQSQVIOjil2xTJPDYjGrhZTOHkoiuPFJRp_zhhsqfoIOkqzIRZnVETkubEZMWMknT1GYHDkx0CZk12P1ZaknVJJdgX3MYjDReQvX2Jdwrr4pqZttou3Hg5_HroJMagbLuO9q3MQ1WMQj7OQ/file\nReusing existing connection to uc63e782d7b0d99570614d32615c.dl.dropboxusercontent.com:443.\nHTTP request sent, awaiting response... 200 OK\nLength: 1163525370 (1.1G) [application/zip]\nSaving to: ‘food11.zip’\n\nfood11.zip          100%[===================>]   1.08G  83.3MB/s    in 13s     \n\n2025-06-24 06:38:24 (83.3 MB/s) - ‘food11.zip’ saved [1163525370/1163525370]\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!unzip -o /kaggle/working/food11.zip -d /kaggle/working/","metadata":{"trusted":true},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"()"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"_exp_name = \"sample\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:42:34.221215Z","iopub.execute_input":"2025-06-24T06:42:34.221809Z","iopub.status.idle":"2025-06-24T06:42:34.225172Z","shell.execute_reply.started":"2025-06-24T06:42:34.221785Z","shell.execute_reply":"2025-06-24T06:42:34.224457Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\nfrom torchvision.datasets import DatasetFolder, VisionDataset\nfrom tqdm.auto import tqdm\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:42:36.952407Z","iopub.execute_input":"2025-06-24T06:42:36.952949Z","iopub.status.idle":"2025-06-24T06:42:36.957620Z","shell.execute_reply.started":"2025-06-24T06:42:36.952926Z","shell.execute_reply":"2025-06-24T06:42:36.956947Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"myseed = 6666  # set a random seed for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(myseed)\ntorch.manual_seed(myseed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(myseed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:42:39.061745Z","iopub.execute_input":"2025-06-24T06:42:39.062529Z","iopub.status.idle":"2025-06-24T06:42:39.069793Z","shell.execute_reply.started":"2025-06-24T06:42:39.062497Z","shell.execute_reply":"2025-06-24T06:42:39.068867Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"test_tfm = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n])\ntrain_tfm = transforms.Compose([\n    transforms.RandomHorizontalFlip(), # 随即水平翻转\n    transforms.RandomRotation(15), # 随机旋转\n    transforms.ColorJitter(brightness = 0.2)\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:42:46.711409Z","iopub.execute_input":"2025-06-24T06:42:46.711921Z","iopub.status.idle":"2025-06-24T06:42:46.716269Z","shell.execute_reply.started":"2025-06-24T06:42:46.711898Z","shell.execute_reply":"2025-06-24T06:42:46.715463Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"class FoodDataset(Dataset):\n\n    def __init__(self,path,tfm=test_tfm,files = None):\n        super(FoodDataset).__init__()\n        self.path = path\n        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n        if files != None:\n            self.files = files\n            \n        self.transform = tfm\n  \n    def __len__(self):\n        return len(self.files)\n  \n    def __getitem__(self,idx):\n        fname = self.files[idx]\n        im = Image.open(fname)\n        im = self.transform(im)\n        \n        try:\n            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n        except:\n            label = -1 # test has no label\n            \n        return im,label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:42:52.723852Z","iopub.execute_input":"2025-06-24T06:42:52.724431Z","iopub.status.idle":"2025-06-24T06:42:52.729972Z","shell.execute_reply.started":"2025-06-24T06:42:52.724410Z","shell.execute_reply":"2025-06-24T06:42:52.729086Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"通道数增加：提取更复杂的特征\n尺寸逐步减小：聚焦关键区域\n卷积核大小：常用3x3(兼顾局部和计算效率),kernel_size = 3\n    卷积核大小：小目标用3x3,大目标用5x5\n通道数：按2的倍数增加(经验法则) 64->128->256->512\n    通道数：每层x2,直到显存不足\n步长/填充:保持尺寸用1/1,减半用2/0 stride = 1,padding=1\n   步长：1(保细节)/2(降维)      填充：0/1 padding = kernel_size//2\n全连接层维度：通常在512~4096之间试验，1024->512->11\n\n卷积层堆叠：模拟人脑从整体到局部的识别过程\n池化层：让模型不在乎物体的位置（上下左右都一样）\n通道增加：有更多的检测点(有的专查纹理，有的专查颜色)\n这个神经网络是CNN的经典套路，适合中小型图像分类任务(Kaggle比赛)，如果是更复杂的任务比如医学影像，就需要更深或者更特殊的结构","metadata":{}},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n \n        self.cnn = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0), \n\n            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n\n            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n\n            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n            \n            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(512*4*4, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 11)\n        )\n\n    def forward(self, x):\n        out = self.cnn(x)\n        out = out.view(out.size()[0], -1)\n        return self.fc(out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:42:56.546851Z","iopub.execute_input":"2025-06-24T06:42:56.547613Z","iopub.status.idle":"2025-06-24T06:42:56.554505Z","shell.execute_reply.started":"2025-06-24T06:42:56.547586Z","shell.execute_reply":"2025-06-24T06:42:56.553787Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = Classifier().to(device)\n\nbatch_size = 64\nn_epochs = 8\npatience = 5 # 早停\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\n# 再次使用Adam，考虑了历史梯度方向，形成惯性调参只需要调lr，其他参数用默认值\n# Adam适用于大多数深度学习任务并且更快更稳真乃神器也！","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:42:59.320147Z","iopub.execute_input":"2025-06-24T06:42:59.320432Z","iopub.status.idle":"2025-06-24T06:42:59.459214Z","shell.execute_reply.started":"2025-06-24T06:42:59.320410Z","shell.execute_reply":"2025-06-24T06:42:59.458378Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"train_set = FoodDataset(\"/kaggle/working/train\", tfm=train_tfm)\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\nvalid_set = FoodDataset(\"/kaggle/working/valid\", tfm=test_tfm)\nvalid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:44:20.916756Z","iopub.execute_input":"2025-06-24T06:44:20.917105Z","iopub.status.idle":"2025-06-24T06:44:20.944609Z","shell.execute_reply.started":"2025-06-24T06:44:20.917078Z","shell.execute_reply":"2025-06-24T06:44:20.944081Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"stale = 0\nbest_acc = 0\n\nfor epoch in range(n_epochs):\n\n    # ---------- Training ----------\n    # Make sure the model is in train mode before training.\n    model.train()\n\n    # These are used to record information in training.\n    train_loss = []\n    train_accs = []\n\n    for batch in tqdm(train_loader):\n\n        imgs, labels = batch\n\n        logits = model(imgs.to(device))\n        loss = criterion(logits, labels.to(device))\n        optimizer.zero_grad()\n        \n        loss.backward()\n        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n        optimizer.step()\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n        train_loss.append(loss.item())\n        train_accs.append(acc)\n        \n    train_loss = sum(train_loss) / len(train_loss)\n    train_acc = sum(train_accs) / len(train_accs)\n    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n\n    # ---------- Validation ----------\n\n    model.eval()\n    valid_loss = []\n    valid_accs = []\n\n    for batch in tqdm(valid_loader):\n\n      \n        imgs, labels = batch\n\n        with torch.no_grad():\n            logits = model(imgs.to(device))\n\n\n        loss = criterion(logits, labels.to(device))\n\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n        valid_loss.append(loss.item())\n        valid_accs.append(acc)\n\n    valid_loss = sum(valid_loss) / len(valid_loss)\n    valid_acc = sum(valid_accs) / len(valid_accs)\n\n    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n\n    if valid_acc > best_acc:\n        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n    else:\n        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n\n    if valid_acc > best_acc:\n        print(f\"Best model found at epoch {epoch}, saving model\")\n        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n        best_acc = valid_acc\n        stale = 0\n    else:\n        stale += 1\n        if stale > patience:\n            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:44:35.983216Z","iopub.execute_input":"2025-06-24T06:44:35.983770Z","iopub.status.idle":"2025-06-24T06:54:42.667264Z","shell.execute_reply.started":"2025-06-24T06:44:35.983746Z","shell.execute_reply":"2025-06-24T06:54:42.666541Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61a22d781a764a1e81be4a8104874e5e"}},"metadata":{}},{"name":"stdout","text":"[ Train | 001/008 ] loss = 1.87132, acc = 0.34823\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b936d0d16794e6a8a8e7bc29b5acbba"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 001/008 ] loss = 1.95323, acc = 0.33254\n[ Valid | 001/008 ] loss = 1.95323, acc = 0.33254 -> best\nBest model found at epoch 0, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbf118e6969d4ad5983a1385ea8608e8"}},"metadata":{}},{"name":"stdout","text":"[ Train | 002/008 ] loss = 1.53028, acc = 0.47462\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28e046ec5a404d638372aa504f7b809d"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 002/008 ] loss = 1.80311, acc = 0.42776\n[ Valid | 002/008 ] loss = 1.80311, acc = 0.42776 -> best\nBest model found at epoch 1, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63388ed146464d1cb898d992ae3ecede"}},"metadata":{}},{"name":"stdout","text":"[ Train | 003/008 ] loss = 1.31511, acc = 0.54767\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"735da52179774dc4a22d46a6f1be0acd"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 003/008 ] loss = 1.56109, acc = 0.48811\n[ Valid | 003/008 ] loss = 1.56109, acc = 0.48811 -> best\nBest model found at epoch 2, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b445ace65504fe28b3a366ca081ced5"}},"metadata":{}},{"name":"stdout","text":"[ Train | 004/008 ] loss = 1.14372, acc = 0.60291\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d32c4db62a864ba580148f7e1306fbd0"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 004/008 ] loss = 1.55957, acc = 0.48270\n[ Valid | 004/008 ] loss = 1.55957, acc = 0.48270\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f46f126756541da92732f046cec44e2"}},"metadata":{}},{"name":"stdout","text":"[ Train | 005/008 ] loss = 1.01483, acc = 0.65506\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12fe52b6a3fa43149f2bf267b94c164b"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 005/008 ] loss = 1.35305, acc = 0.55408\n[ Valid | 005/008 ] loss = 1.35305, acc = 0.55408 -> best\nBest model found at epoch 4, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"944f36721ad04d66a241bcb366e3f545"}},"metadata":{}},{"name":"stdout","text":"[ Train | 006/008 ] loss = 0.88709, acc = 0.68859\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecf1dd9110d148f7bc7ff61d62ca34da"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 006/008 ] loss = 1.11980, acc = 0.61912\n[ Valid | 006/008 ] loss = 1.11980, acc = 0.61912 -> best\nBest model found at epoch 5, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77a20e2e3eee4e7d9dab9674a4c74c65"}},"metadata":{}},{"name":"stdout","text":"[ Train | 007/008 ] loss = 0.75974, acc = 0.73985\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e44092dc20d4afcb8d550d8761b62df"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 007/008 ] loss = 1.19049, acc = 0.61437\n[ Valid | 007/008 ] loss = 1.19049, acc = 0.61437\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"542ad879be17427286bfb67738b21d85"}},"metadata":{}},{"name":"stdout","text":"[ Train | 008/008 ] loss = 0.66031, acc = 0.77120\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"754936eca6934a5087a8eebb9e55b145"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 008/008 ] loss = 1.23379, acc = 0.60027\n[ Valid | 008/008 ] loss = 1.23379, acc = 0.60027\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"test_set = FoodDataset(\"/kaggle/working/test\", tfm=test_tfm)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:55:50.800613Z","iopub.execute_input":"2025-06-24T06:55:50.801300Z","iopub.status.idle":"2025-06-24T06:55:50.810382Z","shell.execute_reply.started":"2025-06-24T06:55:50.801275Z","shell.execute_reply":"2025-06-24T06:55:50.809692Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"model_best = Classifier().to(device)\nmodel_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\nmodel_best.eval()\nprediction = []\nwith torch.no_grad():\n    for data,_ in tqdm(test_loader):\n        test_pred = model_best(data.to(device))\n        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n        prediction += test_label.squeeze().tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:56:22.179490Z","iopub.execute_input":"2025-06-24T06:56:22.180084Z","iopub.status.idle":"2025-06-24T06:56:37.363669Z","shell.execute_reply.started":"2025-06-24T06:56:22.180060Z","shell.execute_reply":"2025-06-24T06:56:37.362849Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/47 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c97c02f725044810ba4b483b53b0bfa3"}},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"def pad4(i):\n    return \"0\"*(4-len(str(i)))+str(i)\ndf = pd.DataFrame()\ndf[\"Id\"] = [pad4(i) for i in range(len(test_set))]\ndf[\"Category\"] = prediction\ndf.to_csv(\"submission.csv\",index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T06:59:57.830537Z","iopub.execute_input":"2025-06-24T06:59:57.830865Z","iopub.status.idle":"2025-06-24T06:59:57.856699Z","shell.execute_reply.started":"2025-06-24T06:59:57.830847Z","shell.execute_reply":"2025-06-24T06:59:57.856137Z"}},"outputs":[],"execution_count":47}]}