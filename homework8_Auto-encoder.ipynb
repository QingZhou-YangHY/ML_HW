{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":12317082,"datasetId":7763731}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 8 - Anomaly Detection**\n\nIf there are any questions, please contact mlta-2023-spring@googlegroups.com\n\nSlide:    [Link](https://docs.google.com/presentation/d/18LkR8qulwSbi3SVoLl1XNNGjQQ_qczs_35lrJWOmHCk/edit?usp=sharing)　Kaggle: [Link](https://www.kaggle.com/t/c76950cc460140eba30a576ca7668d28)","metadata":{}},{"cell_type":"markdown","source":"# Auto-encoder \n## Pre-train = Self-supervised Learning不需要label data   Fine-tuning一下就可以用在下游\n## Encoder(Dimension Reduction):vector to vector,输出Embedding,Representation,Code,bottleneck(非常低维的向量).图片是一个高维度的向量.\n## Decoder:vector to vector\n## 希望Encoder的输入和Decoder的输出(reconstruction)尽可能相似\n## 架构很像GAN,多层Network,就是Cycle GAN\n\n### De-noising Auto-encoder,多了一个任务:去掉noises.和BERT一样\n\n## Feature Disentangle:把Embedding的维度和它们对应的资讯对应起来\n## 应用于Voice Conversion,Encoder的输出为内容＋特征,两者拼起来丢入Decoder\n\n## Discrete Representation:Embedding是Binary,是One-hot vector,可以做到Unsupervised的分类.  \n### VQVAE:和Self-Attention很像,Query和codebook里面的Attention比较相似度\n### Text as Representation:文字丢入En,生成word sequence,是文章的Summary,输入De产生Document.En和De都是Seq2seq. 实际上是行不通的.因为产生的Summary is not readable... 所以要加入一个Discriminator(Human written summaries),判断(Real or not).\n### 其实就变成了Cycle GAN,只不过从Auto-Encoder的角度看Cycle GAN\n# Tips:看到没办法train的问题,就用RL硬做,就结束了.\n## Machine的自学能力还是挺强,所以有时候会意想不到他那里学会了新东西，有时候感觉他在胡说八道.\n## Decoder有时候会被当成Generator\n## Auto-encoder中的Encoder可以用来压缩,Decoder用来解压缩,但是会Lossy(失真)\n## 作业为Anomaly Detection:有一些training data用来异常检测.Detecting input x is similar to training data or not.anomaly可以被称为outlier,novelty,exceptions.\n## 难点在于收集资料.异常的资料太少了.所以他不是一个一般的Classification.叫One plus分类问题.Approach:Auto-encoder.","metadata":{}},{"cell_type":"markdown","source":"# 调整一下Model\n# multi-encoder autoencoder\n# add random noise and an extra classifier","metadata":{}},{"cell_type":"code","source":"!pip install -q qqdm\nprint(\"asdfasdf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T06:03:01.179403Z","iopub.execute_input":"2025-06-29T06:03:01.179924Z","iopub.status.idle":"2025-06-29T06:03:04.614871Z","shell.execute_reply.started":"2025-06-29T06:03:01.179895Z","shell.execute_reply":"2025-06-29T06:03:04.613854Z"}},"outputs":[{"name":"stdout","text":"asdfasdf\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nos.environ['KAGGLE_USERNAME'] = 'your_username'  # 替换为你的用户名\nos.environ['KAGGLE_KEY'] = 'your_api_key'    # 替换为你的API key\n\n# 然后下载比赛数据\n!kaggle competitions download -c ml2023spring-hw8\nprint(\"drfqwe\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T06:24:45.990252Z","iopub.execute_input":"2025-06-29T06:24:45.990552Z","iopub.status.idle":"2025-06-29T06:24:46.900034Z","shell.execute_reply.started":"2025-06-29T06:24:45.990526Z","shell.execute_reply":"2025-06-29T06:24:46.899108Z"}},"outputs":[{"name":"stdout","text":"drfqwe\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!unzip ml2023spring-hw8.zip -d /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T06:27:16.993192Z","iopub.execute_input":"2025-06-29T06:27:16.993939Z","iopub.status.idle":"2025-06-29T06:27:41.425546Z","shell.execute_reply.started":"2025-06-29T06:27:16.993917Z","shell.execute_reply":"2025-06-29T06:27:41.424853Z"}},"outputs":[{"name":"stdout","text":"Archive:  ml2023spring-hw8.zip\nreplace /kaggle/working/.gitattributes? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import random\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision.models as models\nfrom torch.optim import Adam, AdamW\nfrom qqdm import qqdm, format_str\nimport pandas as pd\n\nprint(\"dasasdqw\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T06:28:20.291297Z","iopub.execute_input":"2025-06-29T06:28:20.292138Z","iopub.status.idle":"2025-06-29T06:28:20.298029Z","shell.execute_reply.started":"2025-06-29T06:28:20.292105Z","shell.execute_reply":"2025-06-29T06:28:20.297351Z"}},"outputs":[{"name":"stdout","text":"dasasdqw\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"\ntrain = np.load('/kaggle/working/{WORK_DIR}/trainingset.npy', allow_pickle=True)\ntest = np.load('/kaggle/working/{WORK_DIR}/testingset.npy', allow_pickle=True)\n\nprint(train.shape)\nprint(test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T06:40:34.843731Z","iopub.execute_input":"2025-06-29T06:40:34.844643Z","iopub.status.idle":"2025-06-29T06:40:34.870696Z","shell.execute_reply.started":"2025-06-29T06:40:34.844609Z","shell.execute_reply":"2025-06-29T06:40:34.869766Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3354506332.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working/{WORK_DIR}/trainingset.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working/{WORK_DIR}/testingset.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 raise pickle.UnpicklingError(\n\u001b[0m\u001b[1;32m    468\u001b[0m                     f\"Failed to interpret file {file!r} as a pickle\") from e\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: Failed to interpret file '/kaggle/working/{WORK_DIR}/trainingset.npy' as a pickle"],"ename":"UnpicklingError","evalue":"Failed to interpret file '/kaggle/working/{WORK_DIR}/trainingset.npy' as a pickle","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"!kaggle competitions download -c ml2023spring-hw8 -f trainingset.npy -p {WORK_DIR} --force\n!kaggle competitions download -c ml2023spring-hw8 -f testingset.npy -p {WORK_DIR} --force","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T06:40:04.809842Z","iopub.execute_input":"2025-06-29T06:40:04.810232Z","iopub.status.idle":"2025-06-29T06:40:06.891462Z","shell.execute_reply.started":"2025-06-29T06:40:04.810186Z","shell.execute_reply":"2025-06-29T06:40:06.890449Z"}},"outputs":[{"name":"stdout","text":"Downloading trainingset.npy to {WORK_DIR}\n  0%|                                                 | 0.00/135 [00:00<?, ?B/s]\n100%|███████████████████████████████████████████| 135/135 [00:00<00:00, 653kB/s]\nDownloading testingset.npy to {WORK_DIR}\n  0%|                                                 | 0.00/134 [00:00<?, ?B/s]\n100%|███████████████████████████████████████████| 134/134 [00:00<00:00, 630kB/s]\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"# 文件头显示b'version ht'，这不是合法的.npy文件\n# 很可能是Git LFS指针文件或文本文件被错误命名","metadata":{}}]}